{
    "Meeting joining and introductions": [
        "'PERSON13': 'Yeah, okay.'",
        "'PERSON13': 'So it's just half past eeh nine in LOCATION1.'",
        "'PERSON13': 'And ehm, I'm wondering whether we should start, or whether we should still wait for ORGANIZATION3.'",
        "'PERSON24': 'I've just heard them on e-mail.'",
        "'PERSON13': 'Yeah, so I think that we can probably start so that we stick to the schedule.'",
        "'PERSON13': 'I was curious who is PERSON16.'",
        "'PERSON13': 'Do we have a new team member or is it just someone's nickname?'",
        "'PERSON24': 'Oh, sorry, ehm.'",
        "'PERSON24': 'Yes, we have a new team member.'",
        "'PERSON13': 'Yes, that's good that's great.'",
        "'PERSON13': 'Welcome. '",
        "'PERSON13': 'Yeah, I also did - the PERSON11, uh, is also a new person eh, for us.'",
        "'PERSON13': 'He is still remote unfortunately, he cannot come to LOCATION1 due to covid restrictions.'",
        "'PERSON13': 'But I think that he has probably eeh, applied for visa already if if that was possible.'",
        "'PERSON13': 'We'll see or -  it's difficult to to apply, even apply for a for a visa.'",
        "'PERSON13': 'So that's that's a good idea to have new team members here, especially today.'",
        "'PERSON13': 'Uh, okay so, I think that uh,  I'll probably start presenting, so that we test also the uh, the agenda.'",
        "'PERSON13': 'We did one change.'",
        "'PERSON13': 'I'll get to that in in a second.'",
        "'PERSON13': 'So the the lunch is actually moved a little bit later than what was in the original agenda.'",
        "'PERSON13': 'It's now already modified in the Google doc.'",
        "'PERSON13': 'And that's to make the lunch break reasonable a more reasonable in the UK.'",
        "'PERSON13': 'Ah, and it actually also nicely eh, separates the kind of research work packages from the integration in and other work packages.'",
        "'PERSON13': 'So it's the the split is also, ehm, good.'",
        "'PERSON13': 'Uh, I'll start with my slides, uhm, and everybody else eeh, would then always get a chance to present their slides.'",
        "'PERSON13': 'Ehm, so uh, we'll be swapping, uh, the uh, who is presenting from the presentation for for in the in the Zoom call and later in the Webex call tomorrow.'",
        "'PERSON13': 'And also, ehm, I've  asked eeeh, if if there eeh, would be some live demos, and we will see.'",
        "'PERSON13': 'So PERSON5 is not yet here.'",
        "'PERSON13': 'I do not know if he comes eh, at ten.'",
        "'PERSON13': 'Hopefully, he does.'",
        "'PERSON13': 'The idea is that uh, the uh, starting from work package eh, on ASR we would have eh, in the background a subtitling running, uh, or actually paragraph view would be the recommended one for the whole Zoom call.'",
        "'PERSON13': 'So that people who are not uh, following the slides at the moment - who who find the informations that like duplicate that they know that already.'",
        "'PERSON13': 'They can, eh, look at the translations of our English into all, uh, the languages.'",
        "'PERSON13': 'So that will be, eh, ideally, if eh, PERSON2 agrees, eh, and if PERSON5 comes and sets it up, ehm, that would be like an ongoing demo for the morning sessions.'",
        "'PERSON13': '() '",
        "'PERSON13': 'Starting from work package two when people would get the link where to look at that.'",
        "'PERSON13': 'Ah, and then at the lunch break, we would, eh, stop this.'",
        "'PERSON13': 'And after the lunch break, eh, there is the integration work package and as part of that either PERSON24 will show, eh, the videos.'",
        "'PERSON13': 'Eh, If the demo if the live demo is too risky, or, eh -'",
        "'PERSON13': '() '",
        "'PERSON13': 'We will actually do one of the shorter life demos that we did already twice or three times in the past.'",
        "'PERSON13': 'So uh, so that this would be like interactive, eh, extension of the presentations.'",
        "'PERSON10': 'Okay.'",
        "'PERSON24': 'Ah, PERSON6 and PERSON21 just wrote that they will be joining in sixty or ninety minutes.'",
        "'PERSON13': 'Uh.'",
        "'PERSON24': 'So we do not have to -'",
        "'PERSON13': 'Uh, it's probably okay.'",
        "'PERSON13': 'Exactly, yeah.'",
        "'PERSON13': 'So I'll now start presenting -  share screen, eeh, what do I - now the screen.'",
        "'PERSON13': 'So hopefully you, uhm, download pdf, you see my screen now, open with Acrobat Reader '",
        "'PERSON13': 'Yeah.'",
        "'PERSON13': 'That's the one.'",
        "'PERSON13': 'So please interrupt me at any point eh, or at notes - somewhere, if ehm, but not to the chat preferrably.'",
        "'PERSON13': 'Eeh, because the chat is eh eh yeah it's difficult to uh to execute for to realize that something is in the chat.'",
        "'PERSON13': 'And also while talking, eh and that is a warning for tomorrow as well and warning for everybody, while talking the person who is talking is eh quite unable to eh, realize that there is something in the chat.'",
        "'PERSON13': 'So if something terrible is happening, eh, you have to just step in and say it aloud.'",
        "'PERSON13': 'Uh,because the person is focused on the presentation, and and doesn't see doesn't get any notifications about, eh, about that.'",
        "'PERSON13': 'So, eh, chat is eh eh good only for those who are not presenting at the moment.'"
    ],
    "Overview of project and management": [
        "'PERSON13': 'So welcome, eh, to, eh, the review meeting of PROJECT2 and DRY RUN today.'",
        "'PERSON13': 'Uhh, I'm PERSON13 and I would like to present the overview of the project, and some  summary of the, eh, manage- managerial tasks, uhm.'",
        "'PERSON13': 'This is the agenda for the, eh, whole day today.'",
        "'PERSON13': 'So uh, we have thirty minutes block for this overview.'",
        "'PERSON13': 'I think that maybe we could go faster, we'll see.'",
        "'PERSON13': 'And then we have uh, two and half hours, uh, slot for five uh five work package presentations.'",
        "'PERSON13': 'Uh, for each work package there be always twenty or twenty five minutes of of presentations, and some time reserved for questions.'",
        "'PERSON13': 'Uh, so hopefully we will uh, manage, uh to uh, to uh make this timing.'",
        "'PERSON13': 'Uh, then we have one hour break, eh, for lunch.'",
        "'PERSON13': 'Eh, and after the lunch we have three more work packages.'",
        "'PERSON13': 'Two eh, are on integration, and eh, on dissemination.'",
        "'PERSON13': 'These take up thirty minutes again, each.'",
        "'PERSON13': 'And then we have fourth package on ethics and that is shorter, because it is something which was added on top of the project eh, later, and uh, it's - well, well, fifty minutes should be sufficient.'",
        "'PERSON13': 'Uh, we have uh, some extra time there for additional questions.'",
        "'PERSON13': 'Eh, but as said, I would prefer the questions to be, eh,  mentioned, while we are in the respective work package.'",
        "'PERSON13': 'And then there'll be the break for, eh, reviewers and project officer to discuss and then the times slot to uh, to get the feedback from them.'",
        "'PERSON13': 'Eh, so eeh, ideally, eh, by four o'clock in the afternoon in LOCATION1 time we should be finished.'",
        "'PERSON13': 'Here is a summary of, eh, a research and integration, and innovation goals of PROJECT2.'",
        "'PERSON13': 'And actually, eh, a color code what we deem as research, uh, challenges and what we deem as innovation challenges.'",
        "'PERSON13': 'Eeh, so a machine translation, speech translation eh, are areas that have been examined for decades already.'",
        "'PERSON13': 'But, eh, we are moving, eh, to the highly multilingual, eh, space, eh, our main uh, eh, uh, our main exercise, our main use case is, eh, interpreting life translating spoken language at a ORGANIZATION8.'",
        "'PERSON13': 'Eh, uh, starting from six or seven source languages and translating into up to fourty three target languages so that's the highly multilingual aspect.'",
        "'PERSON13': 'We are also focused on improving the document level coherence and document level we mean both for written documents as well as for spoken documents, uh, in the long term,uh.'",
        "'PERSON13': 'Because eeh, cross sentence, eh, phenomenon, maybe even more important, eh, for uh, speech.'",
        "'PERSON13': 'So, uh, these are the speech and translation related goals.'",
        "'PERSON13': 'And we have added one more goal and that goal is highly research.'",
        "'PERSON13': 'So in highly research we do not, eh, expect to achieve something that would really work for users.'",
        "'PERSON13': 'We have a plan to do a demonstrator, but the demonstrator, uh, would be based on a technology, which is very hard to develop.'",
        "'PERSON13': 'And that is automatic summarization of meetings, which we call minuting.'",
        "'PERSON13': 'So, eh, here in you will hear later on in the meeting summarization.'",
        "'PERSON13': 'We want to plot the ground for research and start a solid research on on meeting summarization.'",
        "'PERSON13': 'Provide data of our shared task, and see how far we can get with the technology.'",
        "'PERSON13': 'Uh, but I er, re-, er, repeat again, it's it's a very challenging goal.'",
        "'PERSON13': 'So ORGANIZATION2 is a coordinator.'",
        "'PERSON13': 'The research partners are ORGANIZATION7 and ORGANIZATION14 and we have, eh, the integrator ORGANIZATION11 and one user partner ORGANIZATION3 within the project.'",
        "'PERSON13': 'And one more user partner affiliated to the project and that's the'",
        "'PERSON13': 'ORGANIZATION12 of the Czech Republic.'",
        "'PERSON13': 'And main PROJECT2 event was supposed to, eh, happen in May this year.'",
        "'PERSON13': 'But it was postponed by one year, eh, because of Covid and that's the interpretation at the ORGANIZATION5 congress.'",
        "'PERSON13': 'So here is a summary of achievements in the first, uh, uh, reporting period, in the first eighteen months of the project.'",
        "'PERSON13': 'And you will hear, eh, the details about the progress in the individual work packages later on.'",
        "'PERSON13': 'In the goal of integrating ASR and machine translation into spoken language translation we -'",
        "'PERSON13': 'I'm actually starting with this integration work package because eh, ehm, now in the achievements, becasue we were researchers, uh, who were happy with our models, uh.'",
        "'PERSON13': 'And independently the ASR was very eh, good and the machine translation was very good and then when we tried to put them together we realized \"Oh it's not so easy\", the  interfacing.'",
        "'PERSON13': 'Especially when it's supposed to be live subtitling, the interfacing is is not a perfect.'",
        "'PERSON13': 'Machine translation requires full sentences, while ASR is eh, producing one word at a time.'",
        "'PERSON13': 'Or the ASR is even offline, so it produces the, eh, the transcribed eh, s- speech in one shot.'",
        "'PERSON13': 'So there was big challenge in, eh, in putting these things together.'",
        "'PERSON13': 'But we managed in the first half of the project, we got ready and we can now live subtitle sessions, regardless whether they run in person or remotely.'",
        "'PERSON13': 'And we did a a fair amount of work on on balancing the simultaneity and user experience.'",
        "'PERSON13': 'More could be done there, eh, but now we think that we have the set up, which is usable.'",
        "'PERSON13': 'Ehm, em, obviously, the the final quality, eh, depends very much on the underlying models.'",
        "'PERSON13': 'And there is still a lot of work to be done, especially on the speech recognition for non-native speakers, uh, and also, eh, machine translation was the, eh noisy output of ASR.'",
        "'PERSON13': 'Noisy in  various aspects.'",
        "'PERSON13': 'We'll we'll learn about it in the in the late representations.'",
        "'PERSON13': 'Uh, we ran multiple live presentations and also test sessions,so, so the infrastructure is now, eh, I would say solid and working very well.'",
        "'PERSON13': 'Uh, obviously, the the final end user experience can be still pretty bad.'",
        "'PERSON13': 'It depends on the, eh, on the actual content of the presentation, and many many aspects of how the speech is - pronounced, eh de- delivered, eh, recorded, eh, processed.'",
        "'PERSON13': 'So there there many, eh, many, eh fine points that need to be taken care of.'",
        "'PERSON13': 'Uh, and if the conditions are good, eh, then, eh, and the domain matches the training data, then the performance is sufficient in our small experience so far.'",
        "'PERSON13': 'For research in the the uh, main areas, eh, spee- speech recognition, machine translation, spoken language translation I would like to hear some key achievement from from ASR so I would like to add something here.'",
        "'PERSON13': 'Uh, I think, that for the machine translation,eh, yeah, so if if you have something now please put it to the slides, or or mention it '",
        "'PERSON24': 'Well, uhm, what you could do put in for work package too.'",
        "'PERSON24': 'I guess it would be, uhm, encoder decoder plus attention streaming ASR.'",
        "'PERSON13': 'Mm-hmm.'",
        "'PERSON13': 'Yeah.'",
        "'PERSON13': 'So that's actually, uh, uh -'",
        "'PERSON13': 'Maybe there is the third point there, working towards no no ehh -'",
        "'PERSON13': 'Not yet.'",
        "'PERSON24': 'Yeah that's that -'",
        "'PERSON13': 'That's that's -'",
        "'PERSON24': 'That's that one -'",
        "'PERSON13': 'That's....I see -'",
        "'PERSON24': 'Yes, but it's it's achieved'",
        "'PERSON13': 'Yeh.'",
        "'PERSON13': 'It's achieved.'",
        "'PERSON13': 'Yeah, yeah yeah.'",
        "'PERSON13': 'Okay. So we have this streaming ASR and now it's not quite integrated.'",
        "'PERSON10': 'Well, it is for English.'",
        "'PERSON13': 'It's for English?'",
        "'PERSON13': 'Okay.'",
        "'PERSON13': 'That's great. '",
        "'PERSON13': 'Yeah.'",
        "'PERSON13': 'Uh, so I'll put it there and and please check.'",
        "'PERSON13': 'Eeh, eh for ehm, for machine translation we deployed and improve multilingual models and again you will hear about that at eh in the presentations.'",
        "'PERSON13': 'And similarly we worked on document level, eeh, translation and evaluated it in many ways.'",
        "'PERSON13': 'And also improved eh, it was a secondary phase.'",
        "'PERSON13': 'Eh, that's the work by ORGANIZATION7.'",
        "'PERSON13': 'And,eh, we are working towards eh, eh, ehm, integration of fully neural ASR into the eh, vibrant processing so I just heard today that the English is already integrated.'",
        "'PERSON13': 'But it has not been yet tested thoroughly in our sessions.'",
        "'PERSON13': 'And eh, I have one more question.'",
        "'PERSON13': 'And that's -'",
        "'PERSON24': 'No, it has has been running for quite while '",
        "'PERSON13': 'Now was it?-'",
        "'PERSON13': 'Yeah, but -'",
        "'PERSON24': 'shoul -'",
        "'PERSON13': 'Did we - did we use it eh?'",
        "'PERSON24': 'Normally it should have been the standard one, for example, for the latest demos also.'",
        "'PERSON13': 'Okay, because -'",
        "'PERSON24': 'So -'",
        "'PERSON13': 'Yeah, we were not aware of that.'",
        "'PERSON13': 'So '",
        "'PERSON24': 'Because at the PROJECT3 so I mean -'",
        "'PERSON13': 'Aha.'",
        "'PERSON24': 'We always have both both running.'",
        "'PERSON24': 'But normally at the PROJECT3 it should have already been the sequence good.'",
        "'PERSON13': 'Okay '",
        "'PERSON13': 'Yeah.'",
        "'PERSON24': 'Well, I I was the one who started it, but -'",
        "'PERSON13': 'Yeah.'",
        "'PERSON24': 'But normally it should have been -'",
        "'PERSON24': 'I mean, we are now basically since two three months -'",
        "'PERSON13': 'Mhm.'",
        "'PERSON24': 'more or less running the English neural to neural as standard, so is-'",
        "'PERSON13': 'Okay'",
        "'PERSON24': 'so it's 'cos it is significantly better.'",
        "'PERSON13': 'Okay that's eh, that's very good news, eh.'",
        "'PERSON13': 'So let's go back to the research, uh, the the the the questionaire um, we really need the fingerprints to show this.'",
        "'PERSON13': 'Because we are now we are now eh, eh starting the regular evaluation of eh, the whole set up.'",
        "'PERSON13': 'And we are ready to to have many results, eh, of different versions, but we need to distinguish both versions.'",
        "'PERSON13': 'So the the last red point on this slide is the end-to-end spoken language translation.'",
        "'PERSON13': 'And there the reviewers have explicitly asked us at the last review  to eh, like start doing that.'",
        "'PERSON13': 'So do we have anything?'",
        "'PERSON13': 'I I'm I wrote something in my in the in the report, a progress report, where, er, there was the eh, there was the question, uh and our responses to that   reading and find - I'll check what I wrote there and -'",
        "'PERSON13': 'Recommendation - technical publications were as that -Start end-to-end tech translation-'",
        "'PERSON13': 'Eh, sorry sorry start end-to-end speech to tech translation.'",
        "'PERSON13': 'Maybe taking as a baseline the end-to-end ASR system from work package two.'",
        "'PERSON13': 'Yeah.'",
        "'PERSON13': 'So that was a recommendation number three and I s- reported on our uh, experiments, uh, and and end-to-end SLT under review at EMNLP, right?'",
        "'PERSON13': 'So -'",
        "'PERSON13': 'Yeah.'",
        "'PERSON13': 'So, there is -'",
        "'PERSON13': 'So if you could summarize in this eh, like to this presentation in one point.'",
        "'PERSON13': 'What is our achievement in end-to-end eh SLT?'",
        "'PERSON13': 'So PERSON1 - eh -You may have paper.'",
        "'PERSON12': 'Ehm -'",
        "'PERSON12': 'Yeah, it's okay so we have -'",
        "'PERSON12': 'At ORGANIZATION7  we based and one a piece of machine which we hear about next week'",
        "'PERSON13': 'Uhm hm.'",
        "'PERSON12': 'And then there was a master's thesis.'",
        "'PERSON13': 'Uhm.'",
        "'PERSON12': 'Ehm.Yeah, I don't have to summarize that one one bullet point.'",
        "'PERSON12': 'Uhm I mean, EMNLP paper concerned, eh,a way of - sparcifying the -'",
        "'PERSON13': 'Uhm,hm.'",
        "'PERSON12': 'ASR output in order it that give us some quality improvements -'",
        "'PERSON13': 'Uhm, hm.'",
        "'PERSON12': 'and some -'",
        "'PERSON13': 'So it's something we -'",
        "'PERSON12': 'to speed up.'",
        "'PERSON13': 'Yeah, speed, yeah.'",
        "'PERSON12': 'Um, the MSC projects was not a we investigated there the robustness.'",
        "'PERSON12': 'I'm gonna show slide about that later -'",
        "'PERSON13': 'Uhm, hm, yeah.'",
        "'PERSON12': 'Of of the SLT -'",
        "'PERSON13': 'Yeah -'",
        "'PERSON12': 'as compared ASR.'",
        "'PERSON13': 'Yeah.'",
        "'PERSON12': 'So I will - yeah.'",
        "'PERSON13': 'So I'll say working towards and and that -'",
        "'PERSON12': 'Yeah, I mean you you can say something a kind of empty, like we have made some improvements in the  -'",
        "'PERSON13': 'Uhm, hm.'",
        "'PERSON12': 'in the end-to-end SLT architecture.'",
        "'PERSON13': 'Yeah.'",
        "'PERSON12': 'I mean there was another paper from ORGANIZATION14 but is -'",
        "'PERSON13': 'Uhm, hm.'",
        "'PERSON12': 'Really early in the project and -'",
        "'PERSON13': 'Uhm, hm.'",
        "'PERSON12': 'It kind of slipped in as an PROJECT2 acknowledgement.'",
        "'PERSON12': 'I don't know if we should -'",
        "'PERSON13': 'Yeah, it highlight it too much.'",
        "'PERSON12': 'If we should highlight it too much 'cause it was very early.'",
        "'PERSON13': 'Yeah, yeah.'",
        "'PERSON13': 'I'm not going to sight any papers here.'",
        "'PERSON13': 'So -'",
        "'PERSON12': 'Yeah, yeah.'",
        "'PERSON13': 'Was in the work packages mention that and I'll I'll - '",
        "'PERSON13': 'It's good to know that that you have at least something that's that's very important.'",
        "'PERSON13': 'Okay -'",
        "'PERSON12': 'Yeah'",
        "'PERSON13': 'Thank you.'",
        "'PERSON13': 'So that's uh, that was they were the achievement in integration and research in ASR machine translation and SLT.'",
        "'PERSON13': 'And we also have, eh, achievements in the, eh, speech, summarization or meeting summarization, ehm. '",
        "'PERSON13': 'Here, eh, the achievements are eh so to say, like baseline setting the the the ground for eh, for more, eh.'",
        "'PERSON13': 'It's very hard to get data from people.'",
        "'PERSON13': 'It's very difficult to record meetings and ehm to get permissions to uh, to uh, to use them in research.'",
        "'PERSON13': 'We we nevertheless managed to con- convince ourselves.'",
        "'PERSON13': 'And by the way, this call is also recorded,  which you know, from from our previous calls.'",
        "'PERSON13': 'I should have said that at the at the beginning eh, and eh, we'll be collecting the the consents, eh, with the eh, usage of the data soon because we got a new active person now on the on the ethical issues.'",
        "'PERSON13': 'So she knows what eh, should be still improved in the consents.'",
        "'PERSON13': 'And as soon as the consents are, eh slightly improved, we'll ask you again to the re-approve, what we can do with the data.'",
        "'PERSON13': 'Ehm, so anyway, we convinced several fellow projects to provide the data.'",
        "'PERSON13': 'So it's not just us.'",
        "'PERSON13': 'It's other, eh, EU project and I think two Czech projects.'",
        "'PERSON13': 'And we also got, eh, an Institute from the City Council of LOCATION1, who are contributing, eh, their eh, meetings.'",
        "'PERSON13': 'Uh, so hopefully they, they gave an eh, eh approval, and they are giving the data, eh, to us now.'",
        "'PERSON13': 'Uh, and hopefully they will stick to that, because technically they can decide at any point to to like uh, prevent us from using the data.'",
        "'PERSON13': 'But, but we hope to to run the nega- negotiation successfully.'",
        "'PERSON13': 'So we are collecting and analyzating the data.'",
        "'PERSON13': 'Uh, mainly creating a transcript or fixing eh, automatic transcripts and eh, providing summaries where they are not provided.'",
        "'PERSON13': 'And we also tested some baseline models.'",
        "'PERSON13': 'So we have kind of complete processing pipeline.'",
        "'PERSON13': 'And we also tried to short- uhm, to to cut it short eh, to  just to sequence the sequence models on that.'",
        "'PERSON13': 'But the results so far are very poor.'",
        "'PERSON13': 'So eh, the research really has to start.'",
        "'PERSON13': 'And in dissemination we also have some achievements.'",
        "'PERSON13': 'Eh, I'll start with the dissemination towards eh, the public eh, or related areas.'",
        "'PERSON13': 'We are in very close connection with the ORGANIZATION12 of the Czech Republic.'",
        "'PERSON13': 'And for example, we prepared a complete workshop on NLP technologies for them.'",
        "'PERSON13': 'And we'll demonstrate that workshop to them as the dry run.'",
        "'PERSON13': 'This will happen at the ORGANIZATION8.'",
        "'PERSON13': 'It should have happened already in May, but we'll have to wait for that ehm.'",
        "'PERSON13': 'And there, ehm thereby we'll get to present not just our technologies, but the whole area to many public institutions eh, in in one go.'",
        "'PERSON13': 'So the ORGANIZATION12 is around the Europe, eh, eh - and hopefully that will spread also further to other institutions.'",
        "'PERSON13': 'Eh, we're also ah, in close connection with interpreters eh, esp- especially the interpreter and student interpreters ehm, eh at the Faculty of Arts of ORGANIZATION2.'",
        "'PERSON13': 'Eh, but eh, also we we are occassionally talking eh, at interpreter conferences eh, to eh, uh, eh, to like start discussion, and eh, see how we , how our technologies can help them.'",
        "'PERSON13': 'Uh and and how our technologies can eh, s-, eee, how to best best organize who who works on what, ehm, across the fields eh.'",
        "'PERSON13': 'For scientific dissemination we organize the IWSLT shared task ehm, on, ehm,  especially non-native speech translation.'",
        "'PERSON13': 'That was kind of a baseline run, and we will uh, do another run of this eh, uhm.'",
        "'PERSON13': 'Hopefully in connection with the um, ehm, simultaneous eh translation, eh, task, ehm, in two thousand and twenty one.'",
        "'PERSON13': 'And uhm eh, aside from the papers we also eh, did some scientific research eh, uh, dissemination into research community uh, at the User and advisory board meeting in August'",
        "'PERSON13': 'So eh, eh, through individual person links we we hope to uh, to uh, get PROJECT2 known in the community.'",
        "'PERSON13': 'Here is summary of the project in terms of work packages and you are now watching the presentation for work package eight management.'",
        "'PERSON13': 'And then we'll go over all of the other work packages with the lunch break ehm, uhm after work package on minuting.'",
        "'PERSON13': 'Eh, and there will be one more uhm, short presentation on the ethical issues, which is work package nine.'",
        "'PERSON13': 'Eh, here is the summary eh, on management.'",
        "'PERSON13': 'Everybody's involved eh, very little, and we as coordinators, eh have eh, in total closed to year eh, over the three years of duration.'",
        "'PERSON13': 'Eh, that accounts for meetings eh, most of them are remote, eh and eh, all the all the reporting uh, obviously.'",
        "'PERSON13': 'Here is a very rough summary of deliverables and milestones.'",
        "'PERSON13': 'Eh, all deliverables which were due have been submitted.'",
        "'PERSON13': 'Uh, um, we had eh, just a few days eh, delays with two one or two deliverables.'",
        "'PERSON13': 'Eh, so in total, there are to be thirty two deliverables and twenty are completed.'",
        "'PERSON13': 'So the first half of the project is like more packed with deliverables eh, and similarly, for the milestones.'",
        "'PERSON13': 'There again we have a successfully achieved everything, which we could have achieved eh, except for the ORGANIZATION5 Congress that was postponed by one year.'",
        "'PERSON13': 'And again, eh, in total, there'll be sixteen milestones, and we have completed ten of those.'",
        "'PERSON13': 'Uh, here is a summary of the financial aspects of the project.'",
        "'PERSON13': 'Eh, all partners reported reasonable spendings, and uh, some had eh, some minor deviations from eh, planned spending.'",
        "'PERSON13': 'The planned spending is generally, planned proportionally, uh, and ehm, uhm, ehm s- there are no major deviations from the financial plan.'",
        "'PERSON13': 'Eh, ORGANIZATION2 in ORGANIZATION7  spent a little bit less than eh than a the half eh, so that's a reserve for possible, unexpected fluctuation in exchange rate as well.'",
        "'PERSON13': 'And eh, ORGANIZATION11 spent more eh, then the half, and that's because, eh, the integration ehm, is eh, hm, needed much more and it was planned to need much more afforts eh, at the beginning of the project then later on.'",
        "'PERSON13': 'So you see eh, the spendings plotted eh, here in the graph.'",
        "'PERSON13': 'Overall the project is eeh, roughly at the half or little bit less than half of it's cost.'",
        "'PERSON13': 'Eh, and ORGANIZATION2 and ORGANIZATION7  are are below the half slightly.'",
        "'PERSON13': 'Eh, ORGANIZATION14 is almost perfect.'",
        "'PERSON13': 'And and ORGANIZATION11 has spent a little bit more and ORGANIZATION3 is also eh, some- somewhat under spending.'",
        "'PERSON13': 'Uhm person months, eh, activity eh, here again we we see that in most work packages eh, well, in total we eh, are at half, eh so that's that's good.'",
        "'PERSON13': 'Uh, some of the work packages eh, seem to have exhausted their work plan person months available, such as the work package one on data.'",
        "'PERSON13': 'Here uh, we actually expect an overspending in person months, not in money, uh, because a lot of annotation work is done, uh, by people who are eh, s-on on lower salaries, and not so eh, eh, so no, no high skills are needed for that.'",
        "'PERSON13': 'Uh, so the person months are eaten up faster eh, than ehm, mm, than the corresponding money.'",
        "'PERSON13': 'And uhm, what is this.'",
        "'PERSON13': 'What is work package six.'",
        "'PERSON13': 'That's the integration - ehm -'",
        "'PERSON13': 'Uh, that's too bad -'",
        "'PERSON13': 'So ss- ehh, so the problem that I see here, but I don't - I won't say that aloud uhm, that is that the integration is underspent in terms of person months.'",
        "'PERSON13': 'Uh, but we are saying that integration is the main cost of ehm, uhm, uhm of ORGANIZATION11.'",
        "'PERSON13': 'So eh, please double check eh, eh ORGANIZATION11, double check eh, the header of work package six.'",
        "'PERSON13': 'How many person months are from other eh, partners.'",
        "'PERSON13': 'It could be that these remaining person months are from other partners, but I actually doubt it.'",
        "'PERSON13': 'But yes they could be from ORGANIZATION3.'",
        "'PERSON13': 'So eh, so get in touch with eh, eh, ORGANIZATION3 and and double check like how to explain this.'",
        "'PERSON13': 'I'll try not to uh, draw attention to this point.'",
        "'PERSON13': 'Uh, but it could seem as an inconsistency.'",
        "'PERSON13': 'It can be explained by the different partners, eh, contributing to this work package, but we need to check, if this holds.'",
        "'PERSON24': 'Okay.'",
        "'PERSON13': 'Yeah, uh-huh.'",
        "'PERSON13': 'Okay.'",
        "'PERSON13': 'Then everythings is like on on track.'",
        "'PERSON13': 'Eeh, and to briefly summarize the um, the research results.'",
        "'PERSON13': 'I'm not going to mention all of them now.'",
        "'PERSON13': 'Eh, but eh, s-  we are really obviously publishing papers and acknowledge PROJECT2 project.'",
        "'PERSON13': 'Eeeh, we have to admit that despite the recommendations, the the papers, so far are mai- mainly site specific.'",
        "'PERSON13': 'So ORGANIZATION2 has eleven papers on machine translation training techniques, test suits and eh, evaluation, eh, including the process of of uh, training eh, and summarization data.'",
        "'PERSON13': 'ORGANIZATION7  has seven uh, papers mai-mainly the document level machine translation, large capacity and efficient neural models.'",
        "'PERSON13': 'ORGANIZATION14 has ten papers ehm, ehm experiments with Transformer- style models for ASR I assume.'",
        "'PERSON13': 'Ah, ah, and also for SLT I'll write it down.'",
        "'PERSON13': 'Eh,  so it is fifteen ORGANIZATION14 for ASR plus SLT, yeah?.'",
        "'PERSON13': 'And we have one join paper.'",
        "'PERSON13': 'That was an overview paper eh ehm at workshop on platforms.'",
        "'PERSON13': 'So we were highlighting the infrastructure of PROJECT2 in that paper .'",
        "'PERSON13': 'Unfortunatell-'",
        "'PERSON12': 'S-'",
        "'PERSON13': 'Yeah'",
        "'PERSON12': 'Sorry PERSON13 there was was the IWSLT paper as well, which -'",
        "'PERSON13': 'Oh'",
        "'PERSON12': 'surely is surely is on every one or it's a -'",
        "'PERSON13': 'That's right -'",
        "'PERSON12': ''cause mos -'",
        "'PERSON13': 'Yes -'",
        "'PERSON12': 'Most of the project -'",
        "'PERSON13': 'Yes,yes'",
        "'PERSON12': 'PROJECT2'",
        "'PERSON13': 'Yes yes, yes.'",
        "'PERSON13': 'IWSLT system paper.'",
        "'PERSON13': 'So the thing is that possibly this was eh, just after the end.'",
        "'PERSON13': 'But let's put it in.'",
        "'PERSON13': 'Let's -'",
        "'PERSON12': 'So it's not it the eighteen month period.'",
        "'PERSON13': 'Eh, let's let's write one plus one there.'",
        "'PERSON13': 'So that it's clear.'",
        "'PERSON13': 'So, un- unfortunately, our ASL paper was rejec- rejected and one of ther reviwer said there is nothing to demo.'",
        "'PERSON13': 'Eh, I'm now investigating the ORGANIZATION6 demo sessions.'",
        "'PERSON13': 'The web page for ORGANIZATION6 is blank eh, for demos.'",
        "'PERSON13': 'Eh, so there is a paper submissions.'",
        "'PERSON13': 'And if there is no demos, then I will probably aah, try to make it a short paper uh, at ORGANIZATION6.'",
        "'PERSON13': 'So let's let's try resubmit for ORGANIZATION6.'",
        "'PERSON13': 'Either at the the demo session or short paper.'",
        "'PERSON13': 'So hopefully we'll we'll get through eh, there.'",
        "'PERSON13': 'Uh -'",
        "'PERSON4': 'PERSON13 -'",
        "'PERSON13': 'Yeah -'",
        "'PERSON4': 'PERSON13, just just just a note regarding the -'",
        "'PERSON13': 'Mhm.'",
        "'PERSON4': 'spent PM -'",
        "'PERSON13': 'Ehm hm.'",
        "'PERSON4': 'Eeh, we have eh, forty-six eeh, PMs on WP6 -'",
        "'PERSON13': 'Ehm hm.'",
        "'PERSON4': 'Only spent by ORGANIZATION11 and eh -'",
        "'PERSON13': 'Okay.'",
        "'PERSON4': 'And that we don- we do not have visibility of the PMs spent by ORGANIZATION3 and other partners.'",
        "'PERSON4': 'So I  think that the sum should be double checked.'",
        "'PERSON4': 'Do you -'",
        "'PERSON13': 'Sum should be really double checked, indeed, because when you say that you have fourty-six eh -'",
        "'PERSON24': 'Maybe I found -I found that maybe I'll -'",
        "'PERSON13': 'Yeah, okey.'",
        "'PERSON13': 'So let's do it during the lunch break to figure out what was -'",
        "'PERSON10': 'Thank you.'",
        "'PERSON13': ' So if it was wrong -'",
        "'PERSON4': 'Okay.'",
        "'PERSON13': 'in the in the report as well, then we should uh, like mention it here, uh, we- we'll discuss that, eeh -'",
        "'PERSON4': 'Okay.'",
        "'PERSON13': 'Yeah. '",
        "'PERSON4': 'Okay, thank you.'",
        "'PERSON13': 'Yeah, thanks.'",
        "'PERSON10': 'Ah, eh.'",
        "'PERSON13': 'Ehm, hm?'",
        "'PERSON10': 'Just one quick info because I've just getting that back.'",
        "'PERSON10': 'Actually PERSON8 for PROJECT2 has not one deal sequence to sequence ASR model, so -'",
        "'PERSON13': 'Okay.'",
        "'PERSON10': 'So we can strike for that from the record, we've been just using it internally for our lecture translation sys-'",
        "'PERSON13': 'Okay.'",
        "'PERSON10': 'I'll tell them that we have to figure out how to get it '",
        "'PERSON13': 'Yeah, yeah exactly.'",
        "'PERSON13': 'So this is s- eh, eh ehm ehm hm for other systems integration '",
        "'PERSON13': 'Yeah, eeh, so I'll be very curious to see the eeh, the difference in in in performance then.'",
        "'PERSON13': 'Eh, okay.'",
        "'PERSON13': 'And then there is also very short summary of the impact of eh, the Covid pandemic on our project.'",
        "'PERSON13': 'No deviations from the plan would have occurred if there were not the pandemic because we'll we'll be otherwise fully on track.'",
        "'PERSON13': 'Now the most important change is the ORGANIZATION5 Congress been rescheduled eh, for spring next year.'",
        "'PERSON13': 'Uh, this is still within the lifetime of the project.'",
        "'PERSON13': 'So that's that's good.'",
        "'PERSON13': 'Uh, but uh, still we would seek eh, an extension of the of the project, also, in order to get eh, time for analyzing the the results of of this ORGANIZATION8 analyzing the the logs and and seeing how the systems performed.'",
        "'PERSON13': 'Maybe some of the data would be limited, uh, only for the duration of the project.'",
        "'PERSON13': 'So uh, we would like to have more time to to explore that.'",
        "'PERSON13': 'Eh, with no conferences and live life event happening, the showcasing of our demos eh, and the the dissemination with eh, paper flyers became harder or a postponed.'",
        "'PERSON13': 'Eh, also we cancelled one of our meetings, um.'",
        "'PERSON13': 'So these are, uh, uh, the the main limitations that we have uh, suffered now.'",
        "'PERSON13': 'Uh, the the real trouble uh, is that eh, is difficult to hire people, uh, and get them to uh, to come to a the respective partners.'",
        "'PERSON13': 'Eh, so the hiring process is is very much complicated.'",
        "'PERSON13': 'And uh, we are uh, es- l- uh, hm, persuading hard eh, or or fighting hard with our personal uh, departments to to get people employed remotely.'",
        "'PERSON13': 'But it's not easy.'",
        "'PERSON13': 'And also remote collaboration is a bit more time demanding, because you need to plan the meetings and and and synchronise eh, carefully and time zone differences are also sometimes a problem.'",
        "'PERSON13': 'So it's uh, the the communication is somewhat slower.'",
        "'PERSON13': 'So that's eh, why we will seek for a non-costed extension of the project, by about three months eh, for mainly for analysis of ORGANIZATION8 results.'",
        "'PERSON13': 'And uh, their better exploitation, and also to eh, cover up eh, from the ehm, hm, more complicated communication.'",
        "'PERSON13': 'So here is the conclusion.'",
        "'PERSON13': 'So far everything looks well.'",
        "'PERSON13': 'Eeeh, submission of deliverables and milestones is almost on time.'",
        "'PERSON13': 'Uh, all partners are aware of their financial situation, and everybody is cooperating very smoothly.'",
        "'PERSON13': 'Technical problems are there, obviously, but they are working on, eh, they are being worked on and solved as we get them.'",
        "'PERSON13': 'Uh, and yes, we are publishing papers, but we still need to improve the cross-side collaboration.'",
        "'PERSON13': 'The pandemic takes the toll of more complicated communication and and hiring, but otherwise it doesn't prevent us from eh, progress.'",
        "'PERSON13': 'So um, that's that's from me.'",
        "'PERSON13': 'I'll do this few changes.'",
        "'PERSON13': 'If you have any other ideas that I should put here, please, let me know.'",
        "'PERSON13': 'And otherwise, uh, let's follow the agenda.'",
        "'PERSON13': 'Uh, so -'",
        "'PERSON24': 'Okay'",
        "'PERSON13': 'Uh -'",
        "'PERSON24': 'Should I put in the contact with PERSON8?'",
        "'PERSON13': 'Uhm, so it is PERSON24 eh, and then PERSON5, and PERSON10.'",
        "'PERSON13': 'They they all designed this or discussed how this should be done.'",
        "'PERSON24': 'Okay, we will.'",
        "'PERSON13': 'So it's important that uh, that we know that from eh, from the outside what is what is running.'",
        "'PERSON13': 'Yeah.'",
        "'PERSON13': 'And let's move on to work package one, right?'",
        "'PERSON12': 'Okay.'",
        "'PERSON12': 'Can you -'",
        "'PERSON12': 'Can you hear me PERSON13?'",
        "'PERSON13': 'Yes, yes.'",
        "'PERSON13': 'Can you already present?'",
        "'PERSON13': 'Or do I have to do something?'",
        "'PERSON12': 'Okay, let me try.'",
        "'PERSON13': 'This would be different in the Webex.'",
        "'PERSON13': 'Uhm, uhm -'",
        "'PERSON12': 'Okay, hopefully you can see -'",
        "'PERSON13': 'Yes.'",
        "'PERSON12': 'my slide.'",
        "'PERSON13': 'Yes.'",
        "'PERSON12': 'Okay, great.'",
        "'PERSON12': 'Okay, brilliant.'",
        "'PERSON12': 'Just check I can - scroll through -'",
        "'PERSON12': 'Okay.'",
        "'PERSON12': 'Okay, I think we could.'",
        "'PERSON12': 'And we have some time for questions.'",
        "'PERSON13': 'Great, thanks.'",
        "'PERSON13': 'Eh, so I would like to warn everybody,including myself that we should always think that we have really at most twenty five minutes.'",
        "'PERSON13': 'Uh, I think you you also like to use your time very well.'",
        "'PERSON13': 'But I know that I have this problem that when I remember, I should be finished by half.'",
        "'PERSON13': 'I will be finished by half eh, and that I will actually eat up all the time for questions.'",
        "'PERSON13': 'Eeh, so, eh, so everybody think about a really delivering shorter presentations than what is the full time slot.'",
        "'PERSON13': 'But it was good like I I do not think that there will be many questions eh I think it's it's okay.'",
        "'PERSON12': 'Okay, good.'",
        "'PERSON13': 'Yeah, thank you.'",
        "'PERSON18': 'May I have a question about the edg- ethical issues concerning the data?'",
        "'PERSON12': 'Oh, okay, yeah.'",
        "'PERSON13': 'And let's move on to the next um um, uh, next presentation, right, which is work package two and that's actually ehm PERSON2 you.'",
        "'PERSON24': 'Okay. '",
        "'PERSON24': 'I need to quickly set it up here into presentation mode.'",
        "'PERSON24': 'Eeeeh '",
        "'PERSON24': 'That' s not -'",
        "'PERSON24': 'Okay, so the slides are not one hundred percent finished yet.'",
        "'PERSON24': 'You'll see one or two gaps that I will need to close till tomorrow.'",
        "'PERSON24': 'By the way ah, ehm, PERSON13, is PERSON7 available for questions, if necessary or should I ask -'",
        "'PERSON13': 'Yeah'",
        "'PERSON24': 'PERSON10?'",
        "'PERSON13': 'Eh, so well I'll uh, I'll try to get PERSON7 Polak also for the call.'",
        "'PERSON13': 'Eh, He is, I'm I'm sure he is not in LOCATION1.'",
        "'PERSON13': 'He is in Slovakia eh at the moment.'",
        "'PERSON24': 'Yeah, I mean I don't need him right now.'",
        "'PERSON24': 'But if a  e-mail her - .'",
        "'PERSON13': 'Yes, yes, yes, yes, yeah.'",
        "'PERSON24': 'Okay that's it. Because I might have would like to ask -'",
        "'PERSON13': 'Yeah.'",
        "'PERSON24': 'to check double check the  from putting together.'",
        "'PERSON13': 'Yeah.'",
        "'PERSON24': 'and make sure that I'm not  t- telling any lies, yeah '",
        "'PERSON13': 'Yeah.'",
        "'PERSON24': 'or misspresenting anything.'",
        "'PERSON24': 'Okay, let' see.'",
        "'PERSON24': 'Ah, um, was, um, are you still there?'",
        "'PERSON24': 'Because -'",
        "'PERSON13': 'Yes, yes, yes, sorry, sure.'",
        "'PERSON24': 'Because somebody took away my Zoom window.'",
        "'PERSON24': 'Sorry.'",
        "'PERSON13': 'Oh.'",
        "'PERSON13': 'Yeah, we we can hear you.'",
        "'PERSON24': 'Okay, good.'",
        "'PERSON24': 'And you can see the screen still?'",
        "'PERSON13': 'Yes.'",
        "'PERSON24': 'Okay, sorry.'",
        "'PERSON13': 'There was, yeah, very good results.'",
        "'PERSON13': 'The video.'",
        "'PERSON13': 'I think it would be very useful.'",
        "'PERSON13': 'But I don't think it is possible to eh, technically it should be possible to stream it through, eh, Zoom.'",
        "'PERSON13': 'But would you uh, uh, be able to uh, to pu- put it somewhere, and like share a link so that people can see -'",
        "'PERSON24': 'I can I can also just put a picture in it.'",
        "'PERSON24': 'I mean it's not that static.'",
        "'PERSON13': 'Yes.'",
        "'PERSON13': 'So maybe yeh.'",
        "'PERSON13': 'So maybe if you but I would be curious myself, uh.'",
        "'PERSON24': 'Yeah I -'",
        "'PERSON13': 'So, share internally and and put a picture into the into the slides that would be the best combination.'",
        "'PERSON24': 'I mean the the video on here that's a link to YouTube, so you can just -'",
        "'PERSON13': 'Oh, so then then simply put the YouTube Link to the slides.'",
        "'PERSON13': 'And and and and then maybe picture that's that's ideal.'",
        "'PERSON13': 'And also uhm, I would like to know more about this.'",
        "'PERSON13': 'Do we have -'",
        "'PERSON13': 'No, we don't have the the right person from eeh from our team here.'",
        "'PERSON13': 'But we have a plan for something which we call censorship, or uh, the eh eh, and the idea is that a live while they system is running.'",
        "'PERSON13': 'Uh, we'll have a module, which would be operated by human eh, to eh, to like eh on the spot fix eh, serious problems in the pipeline.And maybe your user interface is is the best fit for that is  -'",
        "'PERSON24': 'We actually we we also have that in there.'",
        "'PERSON24': 'So ehm you can  -'",
        "'PERSON13': 'Hm, em.'",
        "'PERSON24': 'you can also use the interface to do life fixes.'",
        "'PERSON13': 'So there were very few typos in in your slides,'",
        "'PERSON24': 'Yeah, I know I still I still -'",
        "'PERSON13': 'So if if you open, if you open the slides for editing I can try to -'",
        "'PERSON24': 'Oh you've you've -'",
        "'PERSON13': 'Eh.'",
        "'PERSON24': 'You have editing rights, but I  -'",
        "'PERSON13': 'I don't I don't.'",
        "'PERSON13': 'Eeeh so maybe put it to my uh, gmail account.'",
        "'PERSON13': 'PERSON13 dot PERSON13  at gmail dot com.'",
        "'PERSON13': 'So for some reason, I was not allowed.'",
        "'PERSON13': 'I asked before.'",
        "'PERSON13': 'I had to click requests edit access.'",
        "'PERSON13': 'And now -'",
        "'PERSON13': 'Yeah, I I still have  view only.'",
        "'PERSON24': 'So it's PERSON13 dot PERSON13  at gmail?'",
        "'PERSON13': 'Yeah, yeah.'",
        "'PERSON24': 'Okay.'",
        "'PERSON13': 'Let's move on to work package eh, three, right?'",
        "'PERSON13': 'If there are no further questions.'",
        "'PERSON1': 'Okay.'",
        "'PERSON13': 'Yeah, great.'",
        "'PERSON13': 'Thank you, so please share the screen if it works. '",
        "'PERSON1': 'I'll try and see.'",
        "'PERSON1': 'Share screen, eh, okay.'",
        "'PERSON13': 'Yeah, perfect.'",
        "'PERSON1': 'Does that work?'",
        "'PERSON13': 'Yeah.'",
        "'PERSON1': 'Let's go into presentation.'",
        "'PERSON1': 'Okay you see the typical screen version and -'",
        "'PERSON13': 'Yes, yes'",
        "'PERSON1': 'grey stuff.'",
        "'PERSON13': 'Yes.'",
        "'PERSON13': 'Okay, so if we're all ehh fine with this.'",
        "'PERSON13': 'Then let's move to PERSON10.'",
        "'PERSON13': 'Right?'",
        "'PERSON13': 'Thank you very much.'",
        "'PERSON1': 'Okay, thank you.'",
        "'PERSON13': 'And PERSON10 can start sharing.'",
        "'PERSON10': 'Can you hear me?'",
        "'PERSON10': 'Do I speak?'",
        "'PERSON13': 'Yes.'",
        "'PERSON10': 'Okay,great.'",
        "'PERSON13': 'Yes, that works as well.'",
        "'PERSON10': 'Yeah'",
        "'PERSON13': 'So there is some green window around there green rectangle, but -'",
        "'PERSON10': 'Is there a full slide?'",
        "'PERSON13': 'The slide is full but still, there is some extra green rectangle around that but  -'",
        "'PERSON10': 'Ahhh '",
        "'PERSON10': 'I stop sharing and start again.'",
        "'PERSON10': 'I don't know how to share the entire screen so I could this is -'",
        "'PERSON13': 'Uhm hm.'",
        "'PERSON13': 'Yeah, it is -'",
        "'PERSON10': 'Yeah, so twenty five minutes?'",
        "'PERSON13': 'Yeas, please go ahead.'",
        "'PERSON13': 'Okay, so let's move on -'",
        "'PERSON13': 'Thanks for the other tips and PERSON10 please work on that and we' ll have a look at that later in the afternoon, once you have the all the missing slides ready.'",
        "'PERSON13': 'And let's move on to eh the other work package eeh the next one, which is work package five.'",
        "'PERSON13': 'And that eh I don't if it will be presented by PERSON12 or PERSON14 how you agreed in last few moments.'",
        "'PERSON13': 'So whoever is -'",
        "'PERSON9': 'It will be presented by PERSON14 finally.'",
        "'PERSON13': 'By PERSON14, okay.'",
        "'PERSON13': 'Yeah.'",
        "'PERSON13': 'So we have another team member, PERSON14 Sink.'",
        "'PERSON13': 'Eh she's still located remotely, uh, and she hopefully she will be able to apply for Czech visa eh eh or has come to LOCATION1 to help us with minuting.'",
        "'PERSON13': 'So PERSON14?'",
        "'PERSON13': 'Does it work?'",
        "'PERSON15': 'Can you hear us well?'",
        "'PERSON15': 'I can hear something very quiet, but I don't understand.'",
        "'PERSON13': 'No, it's far from optimal, but   if you can put the microphone closer to your mouth that might help.'",
        "'PERSON15': 'Yes.'",
        "'PERSON13': 'And also thinking of uh, the uh, the connection.'",
        "'PERSON13': 'So now with Zoom it seems that we are lucky that it works.'",
        "'PERSON13': 'But eh tomorrow it will be a different platform, eh the Webex platform.'",
        "'PERSON13': 'And I think it would be still good to have a substitute speaker in case you eeh, face like bad connection eeh issues, because that can easily eh, happen, I'm afraid.'",
        "'PERSON13': 'So eh, well, PERSON12 please be ready to to step in, in case eh, the eh, the connection eeh, fails from from India.'",
        "'PERSON15': 'So, may- I'm more audible now?'",
        "'PERSON15': 'Is eh is -'",
        "'PERSON13': 'Yes, it is it is acceptable.'",
        "'PERSON15': 'Is it -'",
        "'PERSON13': 'It is acceptable. I'll I'll make it louder for myself, and hopefully we'll understand.'",
        "'PERSON13': 'So start sharing your screen.'",
        "'PERSON13': 'If that works.'",
        "'PERSON13': 'Yes.'",
        "'PERSON13': 'That is good.'",
        "'PERSON15': 'Yes.'",
        "'PERSON15': 'Eh, so, okay.'",
        "'PERSON15': 'So So OK so.'",
        "'PERSON15': 'Here I'm going to present minuting module.'",
        "'PERSON13': 'Can I interrupt you?'",
        "'PERSON13': 'Sorry, is that already on the slide somewhere, because I -'",
        "'PERSON15': 'Yeah.'",
        "'PERSON13': 'then you're sharing then your screen is is sharing the wrong eeh, the wrong screen so to say.'",
        "'PERSON13': 'Because I only saw the title slide eh, and -'",
        "'PERSON15': 'Yes.'",
        "'PERSON13': 'and the Adobe Acrobat user interface and not the -'",
        "'PERSON13': 'So if if there should be a slide on this, eeh with listing the tasks and then your talk to that, eh, but I didn't see the slide.'",
        "'PERSON13': 'So -'",
        "'PERSON15': 'Yeah.'",
        "'PERSON13': 'S-Sorry, PERSON14 you came very quiet again.'",
        "'PERSON10': 'Yeah, exactly-'",
        "'PERSON12': 'You were louder earlier.'",
        "'PERSON13': 'Yes.'",
        "'PERSON15': 'Okay, okay.'",
        "'PERSON15': 'Is it is it better now?'",
        "'PERSON13': 'Somewhat better.'",
        "'PERSON13': 'But it was better eh, before.'",
        "'PERSON13': 'And also eh, make make the presentation full screen.'",
        "'PERSON13': 'Control el or ef five.'",
        "'PERSON13': 'Control el is typically.'",
        "'PERSON13': 'Control el, just click control el.'",
        "'PERSON15': 'Eh, just a second.'",
        "'PERSON13': 'Yes.'",
        "'PERSON12': 'Yes that's better.'",
        "'PERSON15': 'Yeah, is it ehm am I audible now?'",
        "'PERSON13': 'Stil too quiet.'",
        "'PERSON15': 'Oh, okay'",
        "'PERSON13': 'But it was better, when you were it was  closer to the mic.'",
        "'PERSON15': 'Is it better now?'",
        "'PERSON13': 'Yes, yes.'",
        "'PERSON15': 'Yes, okay.'",
        "'PERSON11': 'Ah, yes, that's it from me.'",
        "'PERSON11': '() Thank you.'",
        "'PERSON15': 'Ehm,so this is a -'",
        "'PERSON15': 'Yes,yes.'",
        "'PERSON13': 'Is the the end or -'",
        "'PERSON15': 'So do we -'",
        "'PERSON15': 'Yes, so j- do we we would like to invite some questions -'",
        "'PERSON13': 'Yeah.'",
        "'PERSON13': 'So thank you for the presentation.'",
        "'PERSON13': 'I'll I'll send you an e-mail with eeh, like m- multiple comments on that.'",
        "'PERSON15': 'Okay.'",
        "'PERSON13': 'Eh, I think what is very important is to add structure to the presentation itself.'",
        "'PERSON13': 'So eh -'",
        "'PERSON15': 'Mhm.'",
        "'PERSON13': 'You wer eh, uh, th- eh I'll I'll tell you what what has to be there.'",
        "'PERSON15': 'Hm.'",
        "'PERSON13': 'So the- there is one thing, which is the formal division into the shared into the tasks.'",
        "'PERSON15': 'Yes.'"
    ],
    "Progress report Data": [
        "'PERSON12': 'Okay, good morning, my name's PERSON8 I'm from the ORGANIZATION7.'",
        "'PERSON12': 'I'm going to be talking about work package one, which is all about data collection.'",
        "'PERSON12': 'So eh, this poor package provides the other work packages with training and test data.'",
        "'PERSON12': 'And they can use a building systems and for doing their research.'",
        "'PERSON12': 'As well as using the data directly within the project, we release training data publicly where that's possible.'",
        "'PERSON12': 'And we also release test sets, ehm, so they can be used by the wider research community.'",
        "'PERSON12': 'So, here is how the work package is organised.'",
        "'PERSON12': 'It's led by ORGANIZATION7, ehm, ORGANIZATION2 and ORGANIZATION7 Health majority '",
        "'PERSON12': 'It's split into four tasks.'",
        "'PERSON12': 'And I'm going to talk briefly about each of these tasks.'",
        "'PERSON12': 'About what we've done so far, and also about some work that's currently in progress.'",
        "'PERSON12': 'So task one point one is about collecting, and preparing ASR training data and specifically it's about data for Czech.'",
        "'PERSON12': 'And so the background here is the ehm, start of the project.'",
        "'PERSON12': 'We already had ASR systems for six of the seven languages, but we didn't have a Czech system.'",
        "'PERSON12': 'When we go to the project proposal, we'd already identified some sources of transcribed audio data.'",
        "'PERSON12': 'With the Czech national radio being the main one.'",
        "'PERSON12': 'So the objective was to collect data and turn it into a form that's useful for training ASR.'",
        "'PERSON12': 'So for the uh, national radio data, the recordings ehm, come with high quality transcriptions and were taken from various radio programs.'",
        "'PERSON12': 'That ranges from eh, morning news programs to political debates.'",
        "'PERSON12': 'And the original recordings were suitable for training speech were those just because they are too long, typically twenty to fourty minutes long now is much too long for training acoustic models.'",
        "'PERSON12': 'So we developed a pipeline and that aligns the audio with the transcripts of the segment level and splits the recordings into much shorter pieces these are about ten to fifteen seconds long.'",
        "'PERSON12': 'This work has resulted in the creation of two hundred and sixty hours of speech training data.'",
        "'PERSON12': 'Using that, we were able to successfully train and deploy Czech ASR system.'",
        "'PERSON12': 'So ehm, a first version was used to the working group on VAT workshop in June last year.'",
        "'PERSON12': 'Subsequently, um, we built built systems using larger volumes of data, including the um, systems that are in in production in a subtitling pipeline.'",
        "'PERSON12': 'So subsequent to the work on the Czech national radio data we've collected over fourteen hundred hours of recordings from the ORGANIZATION15.'",
        "'PERSON12': 'We could just apply same processing pipeline.'",
        "'PERSON12': 'So we now have ehm ASR training data as well, and we took the sub-set of this data so about four hundred and fourty hours, which we have released publicly.'",
        "'PERSON12': 'And the data was described in in our paper that was published earlier this year.'",
        "'PERSON12': 'In addition, we've created our three Czech ASR test sets.'",
        "'PERSON12': 'Um, actually, I think we have a couple more now or ehm -'",
        "'PERSON13': 'Yeah'",
        "'PERSON12': ' to check this.'",
        "'PERSON13': 'Yeah.'",
        "'PERSON12': 'Ehm, so one of those is from eh, Czech radio.'",
        "'PERSON12': 'One's from ORGANIZATION15.'",
        "'PERSON12': 'We also have eh, recordings from ORGANIZATION10.'",
        "'PERSON12': 'And we've been using these to evaluate eh, the Czech Czech ASR system, report some word eh, some preliminary word error rates here.'",
        "'PERSON12': 'And was I think we may have better results, so yeah, I' ll check that as well ehm.'",
        "'PERSON12': 'And of course we're we're actively working on these models.'",
        "'PERSON12': 'Eh, so this task is, eh now complete.'",
        "'PERSON12': 'It was scheduled to to run from months one till six.'",
        "'PERSON12': 'I think it took a little bit longer to get the pipeline running, but yet.'",
        "'PERSON12': 'It's it's done now.'",
        "'PERSON12': 'Uh, we have training data and test data.'",
        "'PERSON12': 'And we've been, eh, yeah actively using them.'",
        "'PERSON12': 'So, task one point two is about collecting data for speaker and accent adaptation.'",
        "'PERSON12': 'Ehm, there are two main aspects to this task.'",
        "'PERSON12': 'Um, and so the first is that we want to have a kind of full back option for ORGANIZATION8 in case our ASR systems struggle to cope with  conditions we have done.'",
        "'PERSON12': 'Um, or if they struggle with the speaker's accents being different from the accents that were present in the training data.'",
        "'PERSON12': 'So our plan is to have re-speakers on an event that will be recorded under controlled conditions.'",
        "'PERSON12': 'And we know in advance who they are.'",
        "'PERSON12': 'So we can trai- train speaker-dependent systems.'",
        "'PERSON12': 'And so that means we need to gather audio data from the re-speakers and adapt to our systems.'",
        "'PERSON12': 'Uhm, at the moment we we don't know who the re-speakers will be.'",
        "'PERSON12': 'And so we will coordinate with ORGANIZATION9 nearer to the the times of the event.'",
        "'PERSON13': 'Yeah.'",
        "'PERSON13': 'So I would more highlight the actual interpreters instead of re-speakers, eh, because uh -'",
        "'PERSON12': 'Okay.'",
        "'PERSON13': 'there is physically less space, uh, so that the re-speakers probably would not fit in the bullets.'",
        "'PERSON12': 'Okay.'",
        "'PERSON13': 'The the plan is still one so select the the interpretation agency to get in touch with the interpreters, and eh, get the interpreters provide some speaker-specific data.'",
        "'PERSON12': 'Okay.'",
        "'PERSON13': 'So the plan holds just highlight interpreters and not re-speakers.'",
        "'PERSON12': 'Okay, fine.'",
        "'PERSON13': 'Yeah.'",
        "'PERSON12': 'I'll make it '",
        "'PERSON13': 'And also maybe the timing of this task.'",
        "'PERSON13': 'So, uh,  I don't think that we need to ask, for an extension.'",
        "'PERSON13': 'It's within the work package.'",
        "'PERSON13': 'But the officially this task is is planned uh, only for the first half of the project, and obviously it it was delayed due to Covid.'",
        "'PERSON13': 'So we may mention this, but I would not make it any serious issue.'",
        "'PERSON12': 'Sure, okay.'",
        "'PERSON12': 'Okay, and the second aspect of the task is about collecting data that can help to make a speech recognition system more robust, and especially the dialect and accent.'",
        "'PERSON12': 'Eh, so one source of non native speech data was the Fair of Student Firms, which was held in LOCATION1 eh, last year.'",
        "'PERSON12': 'And this was an event where high school students gave short presentations about fictitious companies and the pre- presentations had to be given in English.'",
        "'PERSON12': 'The students were non-native English speakers coming from nine different EU countries.'",
        "'PERSON12': 'So we recorded eh, presentations, and we asked the students to transcribe their own recordings.'",
        "'PERSON12': 'This was part of the competition.'",
        "'PERSON12': 'So they had an incentive to to do that.'",
        "'PERSON12': 'Um, we collected a total od thirty nine recordings averaging about ninety seconds in lengths and together with transcriptions.'",
        "'PERSON12': 'And from this we've created a test set, which can be used to test the robustness of recognition systems.'",
        "'PERSON12': 'Now this test set turned out to be extremely challenging, ehm, partly because of the the accents of speakers, and also because of some eh, noisy conditions of the event.'",
        "'PERSON12': 'So there was some background music and people coming in and '",
        "'PERSON12': 'So even um, state-of-the art models that are adapted have have high error rates on the status.'",
        "'PERSON12': 'So it's a really challenging test set.'",
        "'PERSON12': 'We can try to improve against.'",
        "'PERSON12': 'Ehm, this work has been written up.'",
        "'PERSON12': 'It was published at the international conference on statistical language and speech processing last year.'",
        "'PERSON12': 'And it's also part of our test set for the IWSLT eh, twenty twenty shared task.'",
        "'PERSON12': 'So as a way of testing our own systems, and also staging the state-of-the art we organized shared task on non-native speech translation.'",
        "'PERSON12': 'And the data set was drawn from five different sources.'",
        "'PERSON12': 'One was the Antracorp data set.'",
        "'PERSON12': 'The others eh, were some publicly available sources, except for one, which was ORGANIZATION9 working group on VAT data of which the speakers gave us permission to use.'",
        "'PERSON12': 'And that data is within  domain and the others are from different domains.'",
        "'PERSON12': 'For all the sub-sets the source language was English.'",
        "'PERSON12': 'And there were translations into Czech and German.'",
        "'PERSON12': 'And the type of translation varied, so for some it was interpreted and for others it was within translation produced from the transcripts.'",
        "'PERSON13': 'Actually, if I'm not mistaken everything in the end was written from the transcript.'",
        "'PERSON12': 'Oh -'",
        "'PERSON13': 'We also have the interpretation, but it was uh, not -'",
        "'PERSON12': 'Oh -'",
        "'PERSON13': 'aligned enough.'",
        "'PERSON13': 'So it's it's like for for the research to compare the text based translation versus the interpreted translation.'",
        "'PERSON13': 'And uh, so it is part of the data, but eh, for the IWSLT shared task it was I think all text translation.'",
        "'PERSON12': 'Okay, I'll update that.'",
        "'PERSON12': 'Okay, thanks PERSON13. '",
        "'PERSON12': 'Okay so in PROJECT2 we're trying to support ehm, of a huge number of language pairs.'",
        "'PERSON12': 'We have seven ehm, source languages, fourty three target languages.'",
        "'PERSON12': 'And ideally, we are trying, ehm, support every every one of those language pairs and we're also interested in very specific domain and the domain is auditing.'",
        "'PERSON12': 'Because there isn't ready made in- domain parallel corpus covering all those all of the language pairs we'd like.'",
        "'PERSON12': 'Eh, so we can't just go out and download a pre-existing data set.'",
        "'PERSON12': 'So task one point three is all about ehm, collecting data, for empty ESLT that covers as many of the languages as we possibly can.'",
        "'PERSON12': 'And that also includes some in-domain data.'",
        "'PERSON12': 'So one great, resource for machine translation, is OPUS, which is a huge collection of parallel corpora ehm, covering hundreds of language pairs.'",
        "'PERSON12': 'The data covers a wide range of domains and genres.'",
        "'PERSON12': 'There are translations of the Bible, subtitles from movies, Parliamentary proceedings, all kinds of things.'",
        "'PERSON12': 'So we sampled large multilingual parallel corpus, eh, suitable for training the the initial MT systems in the first version.'",
        "'PERSON12': 'We sampled up to one million sentence pairs for each language pair using up-sampling tool.'",
        "'PERSON12': 'The pairs were less data.'",
        "'PERSON12': 'The  corpus have two hundred twenty six million sentence pairs.'",
        "'PERSON12': 'A variant of this was OPUS one hundred, which covers a more diverse and slightly less Euro-centric ehm sort of languages.'",
        "'PERSON12': 'We use that for some research, which you will hear about later.'",
        "'PERSON12': 'And and that is now part of  collection itself.'",
        "'PERSON12': 'We have also been working on an extended data set.'",
        "'PERSON12': 'So this form  the artificial one million sentence pair limit.'",
        "'PERSON12': 'And and that's now in use for training ehm, IMT systems including some of those the or introduction in a  pipeline, and that some of you will see in other recent project images.'",
        "'PERSON12': 'So OPUS can give us a lot of data, but it's it's out of domain for our application.'",
        "'PERSON12': 'So for in-domain data we have to go out in crawl and prepare it ourselves.'",
        "'PERSON12': 'That was another EU project called Paracrawl, which is specifically focused on crawling parallel data from the Web.'",
        "'PERSON12': 'And we've been ehm, using version of their crawling pipeline for our work.'",
        "'PERSON12': 'So we started out by collecting data from one of the websites of the ORGANIZATION12  in ORGANIZATION5.'",
        "'PERSON12': 'And it has given us some monoligual data covering twenty four languages.'",
        "'PERSON12': 'Eh, some of those languages we're able to collect a lot of data.'",
        "'PERSON12': 'For others it was less, it  was more sparse.'",
        "'PERSON12': 'On on the average, we got a yield of fourty thousand sentences per language.'",
        "'PERSON12': 'We're now applying similar approach to extracting parallel corpora from the website of the ORGANIZATION4.'",
        "'PERSON12': 'And this is a really good resource, because the vast majority of the reports are published in all of the languages of the EU.'",
        "'PERSON12': 'So far we have extracted corpora for the pairs including English.'",
        "'PERSON12': 'And that has given us a pretty good yield that on average two hundred and eight thousand sentence pairs per language pair.'",
        "'PERSON12': 'And we're actively working on ehm, the language pairs that don't include English.'",
        "'PERSON12': 'So it was more data to come.'",
        "'PERSON12': 'We have also collected parallel data from a ORGANIZATION13.'",
        "'PERSON12': 'So ahead of the working group on VAT event we collected slides and other materials from the participants.'",
        "'PERSON12': 'And we used these to search through a similar sentences from the parallel corpora of ORGANIZATION13.'",
        "'PERSON12': 'This gave us an in-domain parallel data set, which we split into training and test portions.'",
        "'PERSON12': 'It covers eight language pairs as German to Czech, as well as certain pairs that have English in the source language.'",
        "'PERSON12': 'For the initial event we didn't have time to users to adapt our modules, but we have now used it for domain adaptation experiments.'",
        "'PERSON12': 'But we took models trained on OPUS corpus and fine tuned uh, using a training portion of the in-domain data.'",
        "'PERSON12': 'And in those experiments with saw uhm, some strong improvements in fine tuning when evaluating on these uh, in-domain test sets.'",
        "'PERSON12': 'So this one is a w- work in progress ehm, we're building a multi-parallel, multilingual corpus of speeches, transcripts, translations and simultaneous interpretations from ORGANIZATION10 planary sessions.'",
        "'PERSON12': 'The data cover the years, uh, two thousand and eight to two thousand eleven, when translations in to all twenty three EU languages were available, at least it was twenty three at the time.'",
        "'PERSON12': 'I think Croatian's been added since.'",
        "'PERSON12': 'Ehm, we received permission to use the interpreters voices for research purposes without we publish it, um, but the voices are accessible on the ORGANIZATION10 website.'",
        "'PERSON12': 'So it that's not a big obstacle to releasing the data.'",
        "'PERSON12': 'This is data set that can be used in various ways from treatment in ASR, for example, also in simultaneous SLT and multi-source SLT.'",
        "'PERSON12': 'Eh, so far we've downloaded speeches in eh, the twenty three languages with simultaneous interpretation into Czech, English and German.'",
        "'PERSON12': 'We're processing over twenty eight thousand speeches, not including the .'",
        "'PERSON12': 'Um, so it's sixteen hundred speakers over a hundred hours, and a over eight million words of English transcripts or or translations.'",
        "'PERSON12': 'Um, the distribution of the source languages is is somewhat unequal.'",
        "'PERSON12': 'So that's two hundred and thirty nine hours of English, hundred and ten of German, and then less for other other languages.'",
        "'PERSON12': 'Okay, task one point four is about collecting data for minuting, ehm automatic minuting.'",
        "'PERSON12': 'Its the most challenging task to collect data for um, since there're very few pre-existing resources.'",
        "'PERSON12': 'Um, as a rule we have been collecting and annotating  from scratch.'",
        "'PERSON12': 'So this involves making audio recordings of meetings and and producing transcripts just like in ASR, but also collecting em, pre-prepared agendas and meeting minutes, which may have been created by the organizers, , secretaries of the meeting.'",
        "'PERSON12': 'And then this data eh, has to be manually annotated by two different annotators with the main idea of the annotation ehm, being that we connect segments of the audio recordings or the ASR transcripts with the corresponding items in the minutes.'",
        "'PERSON12': 'We've been collecting data from our own meetings as well as meetings for other EU projects and meetings of of other groups at ORGANIZATION2.'",
        "'PERSON12': 'So far, we've collected approximately a hundred hours of meetings in English, and over fifty hours of meetings in Czech.'",
        "'PERSON12': 'In the English language meetings, most of the participants are non-native speakers.'",
        "'PERSON12': 'So this is actually a really challenging data set for ASR as well.'",
        "'PERSON12': 'This corpus is still under active development.'",
        "'PERSON12': 'So far, it's been used as a test set for some preliminary experiments on meeting summarization.'",
        "'PERSON12': 'And we continue into collecting  data.'",
        "'PERSON12': 'Also, we have an open call for data.'",
        "'PERSON12': 'Um, there's a link to blog posts on the PROJECT2 website.'",
        "'PERSON12': 'And we're hoping to collect recordings and minutes from ehm, more sources with view to running shared task.'",
        "'PERSON12': 'Okay, so those are the four tasks make up the ehm, data work package, ehm  the data need to project diverse and collect it training test data from wide range of sources.'",
        "'PERSON12': 'Ehm, recen- recent initiative starting earlier this year is PROJECT2 test set.'",
        "'PERSON12': 'This is a  repository where we collect together, uh, the data eh, that we use to evaluate our ASR MT and SLT systems.'",
        "'PERSON12': 'Eh, it's a public repository and one of the groups to ehm, adopt our data.'",
        "'PERSON12': 'So we've spent time making sure everything stored in a consistent convenient format.'",
        "'PERSON12': '() consists of mostly Czech, English and German ehm, documents, the eh, primary languages of the project.'",
        "'PERSON12': 'But the goal is to represent all of the PROJECT2 languages ehm, using both in-domain and also general recordings and texts.'",
        "'PERSON12': 'We are coming out of the sixteen hours of original speech and over hundred and fifty original documents.'",
        "'PERSON12': 'And these either ehm within eh, or transcribed from audio resources.'",
        "'PERSON12': 'And most documents are also translated.'",
        "'PERSON12': 'That's either written translation or live interpretation.'",
        "'PERSON12': 'So -'",
        "'PERSON12': 'We are currently working on expanding the data set and providing additional translations and acquiring data traditional languages.'",
        "'PERSON12': 'And in particular, we using this to evaluate our existing SLT systems.'",
        "'PERSON12': 'And as they improved we will be able to provide exact measurement of the progress.'",
        "'PERSON12': 'Okay so to summarize the data work package is on track.'",
        "'PERSON12': 'We collected data from  resources and include direct data that's in-domain through our specialized domain auditing.'",
        "'PERSON12': 'The data is already in use.'",
        "'PERSON12': 'So we're using it train models and for evaluation of both our own systems, and the systems of others and for more shared tasks.'",
        "'PERSON12': 'Um, with the exception of the training data for interpreters at ORGANIZATION5 which we can count until near the time.'",
        "'PERSON12': 'All of that data collection work is either ehm completed or it's it's on the way.'",
        "'PERSON12': 'And that's eh, work is ongoing.'",
        "'PERSON12': 'Ehm, in particularly development of the PROJECT2 test sets collection, ehm, the data gathering for automatic minuting as well as of the SLT data from ORGANIZATION10 and plannary sessions.'",
        "'PERSON12': 'Okay, so that's all for work package one, um, thank you.'"
    ],
    "WP2 Progress report ASR": [
        "'PERSON24': 'So um, I will try to give you an an insight into the research that has been going on at the work package two on automatic speech recognition.'",
        "'PERSON24': 'Um, so the goal of work package two is to develop the uh, speech recognition systems that are needed in the the um, ah, speech, translation pipeline of the PROJECT2 spoken language translation system.'",
        "'PERSON24': 'In an order for the ASR systems to be usable within that system they have to meet a couple of different criteria.'",
        "'PERSON24': 'So they have to eh, transcribe the speech to text, but they also need to be running in real time.'",
        "'PERSON24': 'They need to run with low word based latency.'",
        "'PERSON24': 'That is the time span from a time that the word has spoken till until it is put out.'",
        "'PERSON24': 'And ehm, of course the test run in acceptable performance and for a diverse set of languages.'",
        "'PERSON24': 'So currently the languages of interest that we have identified for PROJECT2 are Czech, German, English, French, Italian, Spanish and Russian.'",
        "'PERSON24': 'And as rough target performances we've set that we want to reach word error rate below fifteen percent.'",
        "'PERSON24': 'Even better if we could go below ten percent.'",
        "'PERSON24': 'Um, so at the outset of the project, the state- of- the-art -'",
        "'PERSON24': 'So we have an ehm, at the outset of the project the state-of-the art was to do our online low latency speech recognition with hybrid HMM/ANN systems that implemented base classifier and consist of an acoustic model that models the class based probability of an audio sequence given foot sequence MP ah,  probability of a work sequence as a language eh, model.'",
        "'PERSON24': 'And these systems could run in streaming mode with real time at low latency, and with an acceptable peroformance.'",
        "'PERSON24': 'So the artificial neural networks of these systems were used for estimating the um emission probabilities in a hidden Markov model.'",
        "'PERSON24': 'And that again was then used to do the acoustic model.'",
        "'PERSON24': 'While the language model was always realized with ANN language models.'",
        "'PERSON24': 'Um, at the same time at the onset of the project there was also quite active research in sequence to sequence models that do not do use an base approach.'",
        "'PERSON24': 'But directly use neural networks to output the optimal most likely word sequence.'",
        "'PERSON24': 'And there were different competing systems there.'",
        "'PERSON24': 'So one was based on a neural ehm, ehm, target training function called connectionist temporal classification or CTC short for optimizing neural networks that do exactly that that output either directly carries word sequences, for example, using long, short term memory networks.'",
        "'PERSON24': 'And there were also, other, uhm, approaches that used an encoder, decoder with attention model that encode an audio signal represented by a feature sequence X into annotation vector and then decode that one into the target se- symbol sequence for except the characters or word.'",
        "'PERSON24': 'That um, even though these models gave better performance than the hybrid models, they were not able to run at low latency and eh, in real in an online streaming mode.'",
        "'PERSON24': 'So at the beginning of the project eh, they were not ah, suitable for our purposes here in PROJECT2.'",
        "'PERSON24': 'Ah, the work package two has a structure of three tasks.'",
        "'PERSON24': 'Ehm, the first task aims at improving the robustness, especially in terms of hybrid ASR systems of the acoustic model so that they are more robust to different factors, such as different speakers, dialects, accents, acoustic conditions, but also domains in terms of topics.'",
        "'PERSON24': 'And ehm for hybrid, the old hybrid systems there were many hm, techniques to deal with these, but with the new neural methods ehm, there was a need now to to invent methods to develop new methods to become more robust against all these factors.'",
        "'PERSON24': 'And to do that for the sequence to sequence model this is especially challenging to find new adaptation ehm methods.'",
        "'PERSON24': 'Ehm, the second task, um, was concerned with adapting the language model, because in the old traditional systems the language model is more or less responsible for being specific to assist a specific domain.'",
        "'PERSON24': 'So the acoustic model have specifity to the acoustic conditions.'",
        "'PERSON24': 'While the language model has the specifity to towards the topics that the speech recognition system um, is supposed to work on.'",
        "'PERSON24': 'And eh, ASR systems the old ones were always best when adapted and tailored to the target domain as closely as possible.'",
        "'PERSON24': 'And that is often difficult, because for many domains, it's difficult to get a matching training data.'",
        "'PERSON24': 'For example, for the ORGANIZATION9 domain it can be difficult to obtain the matching training data.'",
        "'PERSON24': 'So what what here needs to do is we have to learn a Semi-Supervised ur Unsupervised fashion starting from small amounts of subdata and trying to exploit that as much as possible.'",
        "'PERSON24': 'In order to be able to adapt a, eh, background language model that has been trained on a more generic corpus.'",
        "'PERSON24': 'And then the third task is to deal with the fact that in eh, the traditional way that we train ASR systems usually you have a training phase and the tuning phase.'",
        "'PERSON24': 'And once the model is eh, trained and validated it is then sent out into the real world in order to perform in the real system.'",
        "'PERSON24': 'But the models of the system remain static.'",
        "'PERSON24': 'That's the old way.'",
        "'PERSON24': 'But the real world doesn't work that way because ehm, um, the domains, ah, are constantly changing in terms of linguistics.'",
        "'PERSON24': 'For example, new words and topics are invented, other topics and words are being dropped.'",
        "'PERSON24': 'But you also see new eh, speakers, new accents, new dialects et cetera.'",
        "'PERSON24': 'So the environment in which such system operates constantly changes.'",
        "'PERSON24': 'And therefore the systems should not stay static, but should continue to lo- to learn while they are being deployed.'",
        "'PERSON24': 'And that's what we want to do in the third task.'",
        "'PERSON24': 'So with respect to the work package progress.'",
        "'PERSON24': 'Ah, um, as shown in the deliverable two point one, we have provided the first set of ASR systems that can be used in the uh, different showcases of PROJECT2.'",
        "'PERSON24': 'And we have provided um speech recognition systems for and there's Czech, English, French, German, Italian and Spanish.'",
        "'PERSON24': 'And we're while doing that we examined different architecture.'",
        "'PERSON24': 'So the hybrid, HMM/ANN models, then a sequence-to-sequence model, which is more based on encoder decoder plus attention.'",
        "'PERSON24': 'And then a completely new model which is based on the self attention, which in a machine translation way often is called a transformer based model.'",
        "'PERSON24': 'And then for robustness we ehm, looked at different kinds of robustness.'",
        "'PERSON24': 'So we experimented with neural codes for language robustness.'",
        "'PERSON24': 'Eh, we did eh, developed this new transformer base speech recognition system.'",
        "'PERSON24': 'Um, we looked at robustness towards domains and eh, different topics with the encoder eh, decoder based ehm models.'",
        "'PERSON24': 'And then we also um, looked in two ways of making these decoder encoder based models perform in a streaming mode with a low word based latency.'",
        "'PERSON24': 'When it comes to the second task, where we looked at the adaptation of the language models eh, the consortium performed experiments on in Czech for hybrid HMM/ANN systems.'",
        "'PERSON24': 'And then finally, in order to prepare work for the lifelong learning task.'",
        "'PERSON24': 'We created the first interface that allows us to collect manual corrections supervisions from users of a speech translation system.'",
        "'PERSON24': 'And then in the second half of the project we will perform the research on the data that we collect with this eh, interface in order to be able to learn a lifelong fashion.'",
        "'PERSON24': 'Um, this is an overview over the different languages that we covered with the ASR development.'",
        "'PERSON24': 'We've we have HMM/ANN systems and we have encoder decoder based systems eh, with attention.'",
        "'PERSON24': 'And so for all languages Czech, English, German, French, Spanish and Italian hybrid system is available.'",
        "'PERSON24': 'And for English also a first eh, decoder encoder plus attention based system is now available that meets all the development criteria, and actually outperforms the hybrid eh, system.'",
        "'PERSON24': 'Um the interesting thing of the encoder decoder based attention system is that it runs now in streaming mode.'",
        "'PERSON24': 'So you remember from the the intermediate review that we wanted to make a decision on whether we are able to do this actually to do a streaming recognition with this sequence to sequence models.'",
        "'PERSON24': 'And we actually within the first period managed to to achieve that goal, so that we can run now with the latency of two seconds.'",
        "'PERSON24': 'And the really interesting thing is that we don't see really a degradation in word error rate, if you compare that to the offline system.'",
        "'PERSON24': 'So the streaming recognition in English is now basically just as good as the offline recognition.'",
        "'PERSON24': 'And these are not just any numbers.'",
        "'PERSON24': 'But these are really state-of-the art performance on standard benchmarks.'",
        "'PERSON24': 'And an English worker is now available and can be deployed.'",
        "'PERSON24': 'So the the the only thing that we now need to organize is that we have the the uh, available computational resources to run that in large scale.'",
        "'PERSON24': 'Because the neural models need graphical processing units TPUs in order to run.'",
        "'PERSON24': 'Um with respect to the multilingual re- robustness we had experimented with something that we called language uh, codes neural language codes.'",
        "'PERSON24': 'And the idea behind that is that you train the language identification system with the bottleneck and the activation at the bottleneck is a code that represents the properties of the language that you put into the language identification system.'",
        "'PERSON24': 'And now if you put in, er,  a language that you haven't seen during training of the LID system, you still get a neural code out of the LID system that captures in the continuous vector space the properties of that languages.'",
        "'PERSON24': 'And you can use these language codes in order to eh, condition neural networks in order to better adept themselves in an unsupervised/semi-supervised manner to the language that has being put into the recognition system.'",
        "'PERSON24': 'And we did some experiments with this in a CTC set up where we use the neural language codes to modulate LSTM networks that were trained in CTC.'",
        "'PERSON24': 'And the interesting thing is that if you know, multilingual system in the good old days, if you would make several languages together to train a hybrid system, performance would be great.'",
        "'PERSON24': 'But if you now use modulation with LID on the multilingual system, uhm, you can actually bring it at par with a monolingual system.'",
        "'PERSON24': 'So just performs as well as a monoligual system.'",
        "'PERSON24': 'And if we put uh, some more effort into it and have a ah, ah, super network, based on the uh, Meta Pi network.'",
        "'PERSON24': 'We can actually get word error rates that are below of the monolingual system.'",
        "'PERSON24': 'So they um the ASR systems are now actually able to learn from ah, many different languages, and give better performance in one of the languages.'",
        "'PERSON24': 'When it comes to multi-domain robustness, so robustness to different topics, we ehm, know from the par- past that if you have a hybrid system and you train it on a whole  of different training data for different domains, and then you test one specific domain, performance might actually degrade.'",
        "'PERSON24': 'If you like have training data that mismatches your target domain.'",
        "'PERSON24': 'And our working hypothesis was that what we've een from previous research that neural network based ASR systems are more robust to mixing different styles of training data.'",
        "'PERSON24': 'And all hy- hypothesis was that with an encoder decoder based ASR system we even can improve over matched training data if we pool also missmatched training data into the system training.'",
        "'PERSON24': 'So in order to test that hypothesis, we constructed the multi-domain corpus with a total of one thousand six hundred hours of data.'",
        "'PERSON24': 'And this multi-domain corpus was pooled from publicly available data in English.'",
        "'PERSON24': 'And it contained read speech, planned speech, spontaneous speech.'",
        "'PERSON24': 'With respect to topics we had news broadcasts, we had tech talks, we had lectures, we had phone calls.'",
        "'PERSON24': 'And when it comes to signal eh, variations, we had telephone speech, and word bent speech in the training data.'",
        "'PERSON24': 'Eh, so these are the different corpora we had in there and with the different hours, number of hours.'",
        "'PERSON24': 'So you can see that different corpora have different number of hours in their training data.'",
        "'PERSON24': 'And they cover the whole range of these eh, different, three different dimensions that I mentioned before.'",
        "'PERSON24': 'Ah, so what our experiment showed, that actually the encoder decoder based model slot very fell from this multi-domain sets.'",
        "'PERSON24': 'And while hybrid AMM/HMM/ANN models are always best if you train in a single domain condition with a domain adapted language model.'",
        "'PERSON24': 'Ah, with the encoder plus attention based models we can train on this multi-domain car-corpus and get similar hm, word error rates as the specific hybrid, uhm models.'",
        "'PERSON24': 'And in order to do that, we use to technique diff- diff eh, similar to the multilingual experiment that we did before.'",
        "'PERSON24': 'So instead of having a neural language code we now have sort of a neural domain ID code that we also learn from a bottleneck the eh, eh layer from a neural network that tries to identify the domains.'",
        "'PERSON24': 'And we can now condition our networks by pending this domain with  input.'",
        "'PERSON24': 'And if we do that, um, when it comes to in-domain, domain specific testing we get the same word error rate with the hybrid models.'",
        "'PERSON24': 'And the really nice thing is that if we now test on the domain that we have not seen eh, before, so out-of domain corpus that we haven't seen during training.'",
        "'PERSON24': 'These domain conditioned models actually outperform eh, the hybrid eh, models.'",
        "'PERSON24': 'Um, so here's some word error rate numbers that show that we've switched for TED-talks, um, read books, audio books, broadcast news.'",
        "'PERSON24': 'And then Skype calls, the Microsoft spoken language test set as a test sets.'",
        "'PERSON24': 'The MLST test set is the out-of domain test set.'",
        "'PERSON24': 'So if we have the domain specific HMM/ANN models, we basically get the same performance if we have domain-specific HMM/ANN with the multi-domain trained encoder decoder.'",
        "'PERSON24': 'And then if we go to the out-of domain corpus, we see that with the domain conditioning, the encoder decoder is significantly better on the out-of domain corpus than the hybrid ANN- HMM/ANN systems.'",
        "'PERSON24': 'Ah, when it comes to the robustness of the acoustic model, there were also experiments performed with a differed ASR architecture.'",
        "'PERSON24': 'That is a combination of phoneme level acoustic models, so a network that outputs eh, phonemes.'",
        "'PERSON24': 'In the experiment there was Jasper used, which is essentially a convolutional neural network eh, trained to output phonemes using the CTC crit PERSON12.'",
        "'PERSON24': 'And then on top of this acoustic model, a transformer-based translation system performed translation from phonemes to gra- graphemes.'",
        "'PERSON24': 'Ehm, so when this is applied to clean training data, the performance is not really eh, much worse than that of ey, baseline system.'",
        "'PERSON24': 'And this um, performance can be improved when using um, colla- collapted training data.'",
        "'PERSON24': 'That is most similar to what a acoustic model would put out.'",
        "'PERSON24': 'And if it is combined with transformer -'",
        "'PERSON24': 'I will have some more details on the slides eh, on these experiments.'",
        "'PERSON24': 'Then we also looked at robustness to data augmentation because for sequence to sequence end-to-end ASR overfitting is still one of the most prominent models.'",
        "'PERSON24': 'And usually data augmentation is used to counteract that problem.'",
        "'PERSON24': 'Um, most common technique is the specAugment which does spectral and temporal masking and we added some additional techniques.'",
        "'PERSON24': 'For one we added dynamic time stretching, ah, um, with online perturbation in the spectral domain.'",
        "'PERSON24': 'So instead of speed perturbation in the time domain, we hear by avoiding the shifted pitch.'",
        "'PERSON24': 'And we also use sub-sequences sampling in order to have more linguistic data augmentation of the output sequences.'",
        "'PERSON24': 'And when we apply that, we can see that our sequence to sequence models essentially the achieve a word error rate that is uhm, more or less comparable with the best performing systems on switchboard and CallHome.'",
        "'PERSON24': 'And the best performing switchboard is actually a s- combination of five different systems, while we basically reach the same region of word error rate by using one single  system.'",
        "'PERSON24': 'Ehm then, when it comes to the adaptation of the language models that was work performed on Czech.'",
        "'PERSON24': 'Where a Czech hybrid ASR system that was based on Kaldi was adapted to different domains and the adaptation was done on the language model.'",
        "'PERSON24': 'So the different domains that were used to the experiments were ORGANIZATION15 speeches from the ORGANIZATION15, c- speeches in Czech from the ORGANIZATION10 and presentations on computational linguistics, conferences of the ORGANIZATION12 in LOCATION1 and Czech broadcast news.'",
        "'PERSON24': 'And in order to do the adaptation different types of adaptation data was collected like slides, papers, newspaper articles and key words that are later to the target domain.'",
        "'PERSON24': 'And the slides we will also finish futhermore with some results.'",
        "'PERSON24': 'And then finally, for the lifelong learning we had the preparatory work where we are eh, implemented this editor that allows um to -'",
        "'PERSON24': 'If the video - would load - I guess I will replace the video with a just a couple of eh of pictures.'",
        "'PERSON24': 'So where we were able to eh, now have multi-user collaborative edits on transcriptions on translations of recordings of ehm, talks.'",
        "'PERSON24': 'And all different kinds of of spoken language translation se- sessions.'",
        "'PERSON24': 'And then we can exploit these edits in order to do a lifelong learning.'",
        "'PERSON24': 'So what is the outlook for the rest of the project.'",
        "'PERSON24': 'So we now ehm, aim at ehm coming up with encoding decoding encoder decoder plus attention ASR systems for all languages of PROJECT2 to to be used at the PROJECT2 framework.'",
        "'PERSON24': 'We will perform experiments in lifelong learning based on the user edits eh, with ORGANIZATION14 that we got from the ORGANIZATION14 editing platform.'",
        "'PERSON24': 'And we will do more experiments techniques on robustness towards languages, acce- accents, general conditions et cetera for the end-to-end speech recognition systems.'",
        "'PERSON24': 'And some of the things that I can also p- already promise for the next review, but they don't fall into the reporting period of this this review any more is some first recipes for lifelong learning based on eh, fine-tuning looking at different aspects of how how to do the fine-tuning.'",
        "'PERSON24': 'For different things like accents, domains, et cetera and I w- will also report on being able to reach human performance in English ASR in real time and low latency on a switchboard task.'",
        "'PERSON24': 'And with that I am open for your questions.'",
        "'PERSON13': 'Ehm thank you.'",
        "'PERSON13': 'Thank you for the presentation.'"
    ],
    "WP3 Progress report SLT": [
        "'PERSON1': 'Oh Hi, ehm, okay, so I'm PERSON1 and I'm presenting the  work package three spoken language translation.'",
        "'PERSON1': 'Okay, so spoken language translation is essentially it's the bit that joins the ASR and MT together.'",
        "'PERSON1': 'So eh, it's about how we get um, say the noisy output from MT from ASR which is is a spoken style into something resembling subtitles.'",
        "'PERSON1': 'So essentially, we have two different models for doing this.'",
        "'PERSON1': 'Uh, the first is is the one, we're mainly using in production, which is the pipeline model.'",
        "'PERSON1': 'Where ca- we connect together essentially three different systems.'",
        "'PERSON1': 'Eh we have an ASR system to make the transcripts.'",
        "'PERSON1': 'And then we have a componental module which basically ties up the transcript, makes it more suitable for machine translation.'",
        "'PERSON1': 'And then we have the machine translation component.'",
        "'PERSON1': 'We've also been invent- em experimenting with the end-to-end systems where the goal of that is essentially to have one system that takes in the audio and produces the ouput text.'",
        "'PERSON1': 'So with that sort of split in mind -'",
        "'PERSON1': 'Eh, yeah.'",
        "'PERSON1': 'So the way we put together the work package.'",
        "'PERSON1': 'We thought of that as three different tasks.'",
        "'PERSON1': 'So the first task is sort of  ASR ouput  you assume a pipeline system.'",
        "'PERSON1': 'We take the ASR output and we try to make it more suitable for machine translation.'",
        "'PERSON1': 'The second task is sort of coming in the other direction, where we take the the machine translation system and try to make it more try to try to make it better cope with ASR output.'",
        "'PERSON1': 'And third task is way you can edit  together, and just try to do things from it in an end- to- end fashion.'",
        "'PERSON1': 'So that is just the structure.'",
        "'PERSON1': 'This talk is based on the zoom through the different bits of research that we've done in this work package.'",
        "'PERSON1': 'Ehm, em and in terms of their connection with the tasks, what we what we have actually done.'",
        "'PERSON1': 'This is the way we wrote proposal that there is there is quite a lot of tasks that are connected with this idea of how we take online ASR and first to build an MT system that cope with that.'",
        "'PERSON1': 'And secondly, try to build on it online SLT system.'",
        "'PERSON1': 'So we put it that in into three point two, because it is basically about how we convert the MT system to make it deal with the ASR.'",
        "'PERSON1': 'So with that said ehm -'",
        "'PERSON1': 'The first first thing to mention is segmentation '",
        "'PERSON1': 'So segmentation is the bit - it it's not just segmentation.'",
        "'PERSON1': 'It's the bit that goes between the ASR and the MT in a life system.'",
        "'PERSON1': 'And the typical jobs it has to do are things like the normalization, removal of disfluencies, addition of punctuation, dealing with cases and splitting into sentences.'",
        "'PERSON1': 'So we have essentially two segmenters.'",
        "'PERSON1': 'Um, they are both roughly speaking sequence-to-sequence models.'",
        "'PERSON1': 'Um, the reason we have two is that, um, we started off with the ORGANIZATION14 segmenter.'",
        "'PERSON1': 'We found that it was kind of tied to to the ORGANIZATION14's ASR.'",
        "'PERSON1': 'So at at ORGANIZATION2 we started with an another segmentation effort.'",
        "'PERSON1': 'Um, because we're also building ehm, building ASR at ORGANIZATION2.'",
        "'PERSON1': 'Um, so these are these are fairly simple models, which eh, use sequence-to-sequence models and some rules to produce more like  output.'",
        "'PERSON1': 'Ehm, oh, yeah.'",
        "'PERSON1': 'So '",
        "'PERSON1': 'I mentioned at the start that the ASR's online.'",
        "'PERSON1': 'So this is an example of the the output of ASR.'",
        "'PERSON1': 'Um we basically just co-  again these updates and the updates to to do one of two things.'",
        "'PERSON1': 'Either the it's -'",
        "'PERSON1': 'Well, yeah, the the updates either extend ehm the hypothesis, or they rewrite part of the hypothesis.'",
        "'PERSON1': 'And you see, you know, if you look at the last update you can get changes to the segmentation.'",
        "'PERSON1': 'So the ASR is delivered incrementally what we do with the SLT.'",
        "'PERSON1': 'So when we think about how to develop the SLT, the first one of the first things we thought about is, how do we actually evaluate it.'",
        "'PERSON1': 'Ehm, the tradit-traditionally, you know, you evaluate you evaluate MT using BLEU score on sentences.'",
        "'PERSON1': 'This doesn't quite work for the SLT because you have got other things to think about.'",
        "'PERSON1': 'And really they fall into three different that the three different things we wish to evaluate.'",
        "'PERSON1': 'The first thing is the latency.'",
        "'PERSON1': 'So - eh, the latency becomes a bit tricky.'",
        "'PERSON1': 'When you try, let let us think about a system level that we just think of the MT level, you are looking at the delay between receiving that from ASR and producing the translation.'",
        "'PERSON1': 'Ehm, so there are questions about how to how to actually evaluate that.'",
        "'PERSON1': 'I mean how do I actually link the ASR ouput with the translation of that output.'",
        "'PERSON1': 'And then the second thing, which is maybe not obvious is the idea of a flicker.'",
        "'PERSON1': 'So if you're if your ASR is rewriting and extending and you're constantly translating, then you your MT will start rewriting and and reordering and so on.'",
        "'PERSON1': 'So if you just open up  you get this flicker with things move around on the screen.'",
        "'PERSON1': 'Um, so you can measure that using something like edit-distance.'",
        "'PERSON1': 'And the last thing is also the quality.'",
        "'PERSON1': 'Ehm, so it's it's evaluated with, you know, we all know how to evaluate the MT quality.'",
        "'PERSON1': 'Um, we use one of the automatic metrix.'",
        "'PERSON1': 'Ehm the difficulty with ASR output with all the  spoken language is a thing about the segmentation.'",
        "'PERSON1': 'Uhm, and then you have this thing - you have got this extending going on.'",
        "'PERSON1': 'How do we - how do we evaluate that, and what we do is we just evaluate full sentences.'",
        "'PERSON1': 'So thinking about the evaluation we looked around.'",
        "'PERSON1': 'And there is not really any good tools to to do this evaluation.'",
        "'PERSON1': 'So this is something we have been working on.'",
        "'PERSON1': 'We have this thing called LST sorry SLTF which is an open source evaluation tool.'",
        "'PERSON1': 'The idea is for it to be like the sacreBLUE of ehm SLT.'",
        "'PERSON1': 'So uh, we we have a few different versions of different metrix that have been suggested.'",
        "'PERSON1': 'Um, it delegates a sacreBLEU for for evaluation of MT.'",
        "'PERSON1': 'But we have um within SLTF we have evaluations of of the latency and flicker along with the different variants.'",
        "'PERSON1': 'Um, so this was used in IWSLT shared task eh, this year.'",
        "'PERSON1': 'Um, also in the IWSLT shared task we participated as PROJECT2.'",
        "'PERSON1': 'Um, and this give us the opportunity to to try the different tools that we can creating for doing ASR and MT and connect them together.'",
        "'PERSON1': 'So we took I think seven different ASR systems, including online ones, and offline ones.'",
        "'PERSON1': 'And various different combinations of MT systems, and try them all together to choose the best one in a sort of competitive framework.'",
        "'PERSON1': 'And then submitted is as the PROJECT2 system for this non-native SLT task and not only was it not native speech, but it had an online aspects.'",
        "'PERSON1': 'Um and so we had to submit the the time stamps for for our eh, translation.'",
        "'PERSON1': 'And these were judged by the SLTF tool.'",
        "'PERSON1': 'So the conclusions from that task were that non-native speech recognition that's a really hard.'",
        "'PERSON1': 'Um, so the ASR forms did not form very well, for for many reasons, um.'",
        "'PERSON1': 'So the end the pipeline you know, you are getting BLEU score about five.'",
        "'PERSON1': 'So it is not really very good.'",
        "'PERSON1': 'Um, it also fell back into the -'",
        "'PERSON1': 'Through the task we learn to a bit about the evaluation tool and how it worked to evaluate feedback into it's development.'",
        "'PERSON1': 'Um, so moving on to -'",
        "'PERSON1': 'We've been talking about online SLT ehm, so the way we think about this is there's kind of roughly two different methods for doing online SLT.'",
        "'PERSON1': 'Um,  when you've got an online ASR.'",
        "'PERSON1': 'The first method, which is the one we use in  is called the retranslation method.'",
        "'PERSON1': 'And in this method we we saw the MT is more the more the receiver.'",
        "'PERSON1': 'Um, so ASR pushes messages to MT.'",
        "'PERSON1': 'There's two different types of messages .'",
        "'PERSON1': 'Either the ASR extensive stable region.'",
        "'PERSON1': 'So it says, oh you know, this transcription I gave you.'",
        "'PERSON1': 'I'm not gonna change that that is unstable.'",
        "'PERSON1': 'Or it rewrites the unstable region.'",
        "'PERSON1': 'So the unstable region is the bit that may change.'",
        "'PERSON1': 'And it can either ex- get extended, or it can get altered.'",
        "'PERSON1': 'And retranslation approach is really simple.'",
        "'PERSON1': 'It's just like every time, the ASR updates the unstable region the MT translates.'",
        "'PERSON1': 'It doesn't retranslate everything.'",
        "'PERSON1': 'Full sentences are considered complete once are stable so they're they aren't retranslated.'",
        "'PERSON1': 'But I mean, typically, you can have two to three sentences in the unstable region, and they're constantly get retranslated.'",
        "'PERSON1': 'The other option is is the streaming option.'",
        "'PERSON1': 'And this one is sort of CMT as being in control and the MT has two actions.'",
        "'PERSON1': 'Either it can it can wait for more input from the ASR or it can translate and send to user.'",
        "'PERSON1': 'Um, uh, this works a bit differently, because it requires some kind of modified inference and some kind of learning.'",
        "'PERSON1': 'So the MT can learn when to ehm when to retranslate.'",
        "'PERSON1': 'Sorry when to when to translate and when to wait.'",
        "'PERSON1': 'Ehm, so we use retranslation approach 'cause that is really simple.'",
        "'PERSON1': 'We can use that with that standard MT tool ORGANIZATION14, um with a very simple wrapper, um.'",
        "'PERSON1': 'And at the moment, we don't um, we consider flicker to be quite bad.'",
        "'PERSON1': 'Ehm especially if the if the translation isn't very good.'",
        "'PERSON1': 'Then it has flicker a lot.'",
        "'PERSON1': 'So the actual current production rate of the ASR stabilized .'",
        "'PERSON1': 'Ehm, so a couple of things that we can do to improve the retranslation approach.'",
        "'PERSON1': 'The first thing is that ehm if the if the MT system doesn't see prefixes as an ehm, incomplete sentences in training.'",
        "'PERSON1': 'It doesn't do very well.'",
        "'PERSON1': 'So training that prefixes does help.'",
        "'PERSON1': 'And the nice thing is you do not have to mess about the aligners to produce the prefix d- you ju- just truncate.'",
        "'PERSON1': 'I'm  these in training.'",
        "'PERSON1': 'Makes it slightly worsen full sentences but it makes it better on prefixes.'",
        "'PERSON1': 'The other thing we do, which is a simple idea, ehm, from a paper by Arivazhagan is is masking.'",
        "'PERSON1': 'Where basically you don't, you just mask the last key words of the outputs.'",
        "'PERSON1': 'You translate, but you don't send the whole translation you mask the last keywords.'",
        "'PERSON1': 'So that's kind of a blind test meant very simple.'",
        "'PERSON1': 'Eh, but one thing we thought about is can we improve on that?'",
        "'PERSON1': 'Ehm, so we improve by doing something called dynamic masking.'",
        "'PERSON1': 'So if you use a fix mask, you end up with quite a lot of latency.'",
        "'PERSON1': 'I mean in the fix mask it's is shown in a red dotted line in this graph.'",
        "'PERSON1': 'So the graph is showing the latency against the um, the flicker.'",
        "'PERSON1': 'Um, and the way we did dynamic mask, is we try to look look at the translation and predict how how stable it is.'",
        "'PERSON1': 'And we do this by basically extending.'",
        "'PERSON1': 'So we get the source of the from the ASR and we try different extensions of the source.'",
        "'PERSON1': 'We just basically predict what the next source word might be.'",
        "'PERSON1': 'And then try translating them.'",
        "'PERSON1': 'And if we see lot of instability in those translations, then we use a long mask.'",
        "'PERSON1': 'And if we don't see much instability.'",
        "'PERSON1': 'We try try various extensions and use the same thing that we do not alter the mask very much.'",
        "'PERSON1': 'And that gives us a better ehm latency flicker tradeoff.'",
        "'PERSON1': 'So that was work we published at AMSA.'",
        "'PERSON1': 'Um, the next thing is again addressing the latency.'",
        "'PERSON1': 'Basically latency quality trade-off is -'",
        "'PERSON1': 'And this is going to the streaming approach.'",
        "'PERSON1': 'Um, where we we we ex- exploit a a thing called adaptive computation time, which was reduced introduced a few years ago.'",
        "'PERSON1': 'Um and the idea is that worsening code of encoder decoder networks.'",
        "'PERSON1': 'And the essential idea is the decoder.'",
        "'PERSON1': 'So you have the encoder, which takes the input and encodes it, but the decoder has basically two options.'",
        "'PERSON1': 'It can either ponder, so it can wait for more encoder steps.'",
        "'PERSON1': 'Or it can it can produce output.'",
        "'PERSON1': 'We showed this working for essentially machine translation on unsegmented ASR output.'",
        "'PERSON1': 'But our plan is to make this work work for end-to end SLT on completely unsegmented audio.'",
        "'PERSON1': 'So that don't we can do the segmentation as well in the whole pipeline.'",
        "'PERSON1': 'Ehm, okay.'",
        "'PERSON1': 'So this is moving on to thinking about, um, how do we do with the noise in ASR.'",
        "'PERSON1': 'Um so, the noise -'",
        "'PERSON1': 'Sorry.'",
        "'PERSON1': 'The re- MT can suffer, because is essentially trai- a mismatch between training and inference.'",
        "'PERSON1': 'So the training data is using very clean  transcripts or basically clean text.'",
        "'PERSON1': 'Ehm a test time, or or inference time, we are using noisy output of speech recognition.'",
        "'PERSON1': 'So how do you deal with that?'",
        "'PERSON1': 'Well, oa- one way we've looked at is ehm, to try to model the noise.'",
        "'PERSON1': 'So the method is basically to run some data through ASR and look at the errors.'",
        "'PERSON1': 'And then we build a model for creating artificial noise.'",
        "'PERSON1': 'Ehm, and artifical noise basically consists of things like ehm adding  function words, changing function words, changing verb tenses, pluralizing, depluralizing.'",
        "'PERSON1': 'And then a bunch of ehm, let's say acoustic confusion trying to find words and sounds like sound like so inject them to the MT training data and retrain.'",
        "'PERSON1': 'So that gives us a consistent improvement.'",
        "'PERSON1': 'We did some experiments with English to Chinese.'",
        "'PERSON1': 'Ehm, it gives some consistent improvement on the when you're translating ASR output, but not when you're translating gold transcripts, which is what we expect to happen.'",
        "'PERSON1': 'Um, when looking in more details, it's bit a harder to link that to the to the noise models.'",
        "'PERSON1': 'So r- sort of suspecting that there is also regularization going on when injecting this noise, which may be causing the game.'",
        "'PERSON1': 'We are not really sure.'",
        "'PERSON1': 'Um, related to that is another ehm, piece of work we did where instead of instead of translating directly from the audio.'",
        "'PERSON1': 'Sorry it - it's like pipeline approach.'",
        "'PERSON1': 'In the pipeline approach we go from the audio basically to the written text.'",
        "'PERSON1': 'The graphemes, if you like, to add them to the translation.'",
        "'PERSON1': 'But what if you go from the audio to the phonemes.'",
        "'PERSON1': 'So you don't actually go to fill speech represent- eh full writen representation.'",
        "'PERSON1': 'And then you add them to do the translation.'",
        "'PERSON1': 'That could help with the robustness.'",
        "'PERSON1': 'I think it could because you sort - you sort of preserving the different interpretations of those phonemes rather than committing to some written form.'",
        "'PERSON1': 'Ehm, and it could definitelly help if you have a that a language s-ah- transliteration that may well have help with the entities.'",
        "'PERSON1': 'We haven't tested that yet.'",
        "'PERSON1': 'Ehm, we have some results for English to Czech.'",
        "'PERSON1': 'And what it showing is that in this second part of the table with the ASR source source when we use phonemes as the intermediate representation we get some improvements.'",
        "'PERSON1': 'Only at the long, the lower the the larger beam sizes.'",
        "'PERSON1': 'But we get no real difference when we have got a clean beam and that which is kind of what we expect.'",
        "'PERSON1': 'Ehm, so that brings us forward into end-to-end translation.'",
        "'PERSON1': 'Um, where yeah, the idea is, the goal is basically have to take the input and then the output audio and produce a direct eh, trans- translation.'",
        "'PERSON1': 'So what the advantages of that.'",
        "'PERSON1': 'I think that the main sort of ideas that is gonna be a much simpler model.'",
        "'PERSON1': 'You know, we don't have to have to have this complicated deployment pipeline.'",
        "'PERSON1': 'We can have one model, which does the ASR segmentation the MT.'",
        "'PERSON1': 'Eh, connected with that is is is the notion that it should improve the coupling.'",
        "'PERSON1': 'The ASR and the MT should work together, because they train together.'",
        "'PERSON1': 'And it it gives us should give some more efficient inference and make it and should make it simpler to do this online SLT which we are trying to do.'",
        "'PERSON1': 'Um, one of the big problems that has end to end SLT faced is the is the lack of end to end data.'",
        "'PERSON1': 'So basically, you need, say, you need like English audio paired with ehm Czech eh, translations ehm, and there's limited amount of this.'",
        "'PERSON1': 'Ehm, whereas if you want English audio put- if you want to build pipelines system, you have very large amount of English training data.'",
        "'PERSON1': 'And for a translation sets we have a lot of English to Czech translation.'",
        "'PERSON1': 'So the the techniques that we're using is things like um transfer learning system, kind of pre-training some kind of multitask training.'",
        "'PERSON1': 'And we have been developing certain architecture improvements, which help with the get over the  issue.'",
        "'PERSON1': 'Ehm, so on the end to end translation system.'",
        "'PERSON1': 'One of the claims for end to end translation is this this kind of robustness.'",
        "'PERSON1': 'So it should be more resistant to noise.'",
        "'PERSON1': 'So we set out to examine this.'",
        "'PERSON1': 'So I'm going to explain this this this this graph.'",
        "'PERSON1': 'Ehm, we experimented with English to Spanish on end to end translation.'",
        "'PERSON1': 'Ehm, and what we did was, we added increasing decreasing noise to the inference data.'",
        "'PERSON1': 'And that is what the X- axis represents.'",
        "'PERSON1': 'It goes from raw as a no noise to very noisy input.'",
        "'PERSON1': 'And it shows blue on the Y-axis.'",
        "'PERSON1': 'And the pairs of lines are showing an end to end system and a pipeline system.'",
        "'PERSON1': 'So that, for example, the blue solid line and the blue dotted line, both show paired end to end systems and pipeline systems.'",
        "'PERSON1': 'And the different colours represents the different training conditions, we actually injected the noise during training to try different conditions.'",
        "'PERSON1': 'What we see from this is, there isn't really any evidence that the end to end system is more robust.'",
        "'PERSON1': 'Essentially the blue th- the dotted lines and the solid lines are essentially parallel as far as you can see.'",
        "'PERSON1': 'So there isn't strong evidence from here that we are getting more robustness.'",
        "'PERSON1': 'Um, this is this is essentially one one language per one one noise injection.'",
        "'PERSON1': 'Um, but yeah, we don't see any evidence at the moment.'",
        "'PERSON1': 'Further work that we've done on end to end translation has come from this idea that speech signals very data sparse.'",
        "'PERSON1': 'So you, you know, the important parts of containing quite small sections.'",
        "'PERSON1': 'Um, so how do we exploit this.'",
        "'PERSON1': 'The idea is to learn feature selector before we learn the translation.'",
        "'PERSON1': ' have this work.'",
        "'PERSON1': 'Ehm, so the method is as appear in the in the enumeration.'",
        "'PERSON1': 'We first we train the ASR encoder um.'",
        "'PERSON1': 'That were trained as our system, which includes ASR encoder.'",
        "'PERSON1': 'And then we have another phase where we learn this feature selector.'",
        "'PERSON1': 'Um, and feature selector that we use is this is the  cell zero drop, which is up, um, which encourages sparcity, using this L zero-based objective.'",
        "'PERSON1': 'Um, and then we trained the SLT with these just with these selected features, instead of using a full output from ASR encoder.'",
        "'PERSON1': 'And that get rid gets rid an awful lot of the ehm, ASR input and gives us some improvement on Bleu analysis and speed up.'",
        "'PERSON1': 'Like one, let's say one four percent speed up in an inference time.'",
        "'PERSON1': 'I'm showing here results of linguistic German.'",
        "'PERSON1': 'But we actually have pretty similar results across the whole of the massy data sets.'",
        "'PERSON1': 'Um, so that's where we are.'",
        "'PERSON1': 'Ehm, okay.'",
        "'PERSON1': 'So, may- I'm talking on problems here.'",
        "'PERSON1': 'Ehm, '",
        "'PERSON1': 'We have this we still have this flicker latency trade-off pro- problem.'",
        "'PERSON1': 'What we've done that these to date to make it useful make it good for users is to remove flicker altogether.'",
        "'PERSON1': 'That gives a large latency.'",
        "'PERSON1': 'Ehm, I I think possibly if that systems were stronger then flicker wouldn't be such a problem.'",
        "'PERSON1': 'Um, we also find that if if the ASR degrades in the MT MT quality dropped quite rapidly.'",
        "'PERSON1': 'You know, for example, get per per- per acoustics and the MTs becomes very poor.'",
        "'PERSON1': 'But also, we have the wrong segmentation.'",
        "'PERSON1': 'Um, that makes it very difficult for the MT to cope was very difficult thing for the MT to cope with.'",
        "'PERSON1': 'Also the - and this connects a bit with work package five.'",
        "'PERSON1': 'And and also with the  the ideal flicker.'",
        "'PERSON1': 'You you got this notion of cognitive load, if the transcripts are not and the translations are not that good or they're too long and they're flickering, all these things make it very difficult for the user to read.So we're still kind of optimistic that e- end to end SLT was can adress some of these problems.'",
        "'PERSON1': 'You know, for example, dealing with un-segmented audio.'",
        "'PERSON1': 'Uhm, coming about online SLT it does not work much better than that so far.'",
        "'PERSON1': 'And also the notion to try to do to summarization of the same time to make maybe one big model can do everything.'",
        "'PERSON1': 'Um, okay.Thank you.'",
        "'PERSON1': 'That's the end of my presentation.'"
    ],
    "WP4 Progress report MT": [
        "'PERSON10': 'So, hello, my name is PERSON10 and I'm presenting the work package on ma- multilingual machine translation.'",
        "'PERSON10': 'This is the work package overview.'",
        "'PERSON10': 'The leader is ORGANIZATION2 and the participant- paticipating partners are also ORGANIZATION7  and ORGANIZATION14.'",
        "'PERSON10': 'This is the task overview we have to provide.'",
        "'PERSON10': 'So the first task is the baseline models.'",
        "'PERSON10': 'It was scheduled for the first six months of the project.'",
        "'PERSON10': 'And the the objective was to provide the machine translation system between all fourty three ORGANIZATION5 languages for the needs of ORGANIZATION5.'",
        "'PERSON10': 'And also as as a baseline for future research.'",
        "'PERSON10': 'And it was planned for the first six months of the project until the ORGANIZATION8 which was pos- but the the ORGANIZATION8 was postponed so also the need of the of the model is postponed.'",
        "'PERSON10': 'And so far we cover hundred percent of the language pairs by either bilingual or my- multilingual models are piloting.'",
        "'PERSON13': 'Eh, I would be coussious about the experimental ORGANIZATION5 lanugages because I think we still use the English to thirty six and not English to fourty three, right?'",
        "'PERSON10': 'But we have a model which have which has -'",
        "'PERSON13': 'Okay'",
        "'PERSON10': 'which is English to fourty three, fourty three.'",
        "'PERSON13': 'So we have Moldauan and  Montenegran, right?'",
        "'PERSON10': 'If PERSON8 can confirm, I have -'",
        "'PERSON12': 'I think we are actually missing one or two languages still.'",
        "'PERSON12': 'Even in bigger -'",
        "'PERSON13': 'Yeah.'",
        "'PERSON12': 'models yeah, I think Montenegran, is one on eh.'",
        "'PERSON12': 'I don't remeber which others.'",
        "'PERSON12': 'So we don't don't quite have a hundred percent -'",
        "'PERSON13': 'Yeah.'",
        "'PERSON12': 'close.'",
        "'PERSON13': 'So PERSON8, could you could you please check and fix this slide.'",
        "'PERSON13': 'It's the the link is in the agenda.'",
        "'PERSON12': 'Okay.'",
        "'PERSON12': 'Yeah, will do.'",
        "'PERSON13': 'Thank you.'",
        "'PERSON10': 'And so fo-'",
        "'PERSON13': 'And the red color - PERSON10 sorry was that eh eh, it should be there or -'",
        "'PERSON10': 'The the slide is the same as in the last review, but except of the red colour.'",
        "'PERSON10': 'So here was eighty seven percent last year.'",
        "'PERSON13': 'Uhm,hm.'",
        "'PERSON10': 'And this year it is almost hundred percent.'",
        "'PERSON10': 'Yeah and here the the bold bold languages are those that we have covered and the non- bold are the those that we didn'didn't have covered last year.'",
        "'PERSON10': 'Yeah, so the current state of baseline models is that we have bilingual models for some high research language pairs and multilingual for the others.'",
        "'PERSON10': 'And we we use pivoting through English.'",
        "'PERSON10': 'So we can cover all the languages.'",
        "'PERSON10': 'And in PROJECT2 IWSLT submission we we compared the this multilingual model and we selected it as as the best candidate for English to German.'",
        "'PERSON10': 'So actually the gap between multilingual and bilingual for for pivoting is being narrowed by research.'",
        "'PERSON10': 'And it's possible that in future we don't we won't need bilingual models.'",
        "'PERSON10': 'And we would and the ORGANIZATION12 will be okay with with multilingual.'",
        "'PERSON10': 'So the next task is document-level machine translation.'",
        "'PERSON10': 'It's a research task which is scheduled for the all- whole three years of the project.'",
        "'PERSON10': 'In last year we had we had several publications, but we have already reviewed them so I exlude them.'",
        "'PERSON10': 'And this year we have we have testsuite on ORGANIZATION12 documents at WMT twenty.'",
        "'PERSON10': 'It's still under review.'",
        "'PERSON10': 'And I have to finish this slides in the afternoon.'",
        "'PERSON10': 'Next next task is Multi-target MT.'",
        "'PERSON10': 'Again we had some publications last year.'",
        "'PERSON10': 'And the new publication is improving massively is on improving massively in multilingual machine translation.'",
        "'PERSON10': 'Because multilingual NMT is convenient, because it has there has to be be only one neural network which serves many languages at ones.'",
        "'PERSON10': 'And so it's convenient to deploy it.'",
        "'PERSON10': 'But it can underperform.'",
        "'PERSON10': 'And the other works investigated increasing capacity and language specific components.'",
        "'PERSON10': 'But in this work the authors propose random online back translation for improving quality on zero-shot language pairs.'",
        "'PERSON10': 'They tested it on massive scale on ten thousand language pairs, on OPUS one hundered.'",
        "'PERSON10': 'And they narrowed the gap on zero-shots compared to pivot-based translation from seven BLEU points to one BLEU.'",
        "'PERSON10': 'This paper was published at this year ACL.'",
        "'PERSON10': 'Yeah, then we have PERSON23's thesis.'",
        "'PERSON10': 'Also this slide has to be finished in the afternoon.'",
        "'PERSON10': 'The multi-source machine translation has been scheduled for this year.'",
        "'PERSON10': 'We have just sta- started.'",
        "'PERSON10': 'We have an initial multi-source experiments.'",
        "'PERSON10': 'And we observed worse ex- performance than one source.'",
        "'PERSON10': 'Probably on- probably because of the data.'",
        "'PERSON10': 'Therefore, we we're are focusing on preparing the multi-parallel Europen speech and interpretation corpus which was already described by PERSON8 in in work package one.'",
        "'PERSON10': 'And and the idea is that the original ASR and parallel interpreters ASR may have complementary errors.'",
        "'PERSON10': 'And therefore we may use Multi-source for quality enhancements of the ASR and translations.'",
        "'PERSON10': 'And also we may find other applications of of this corpus.'",
        "'PERSON10': 'And we we plan more work.'",
        "'PERSON10': 'Yeah, the flexible, multi-lingual machine translation, is scheduled for next year, and it hasn't started yet.'",
        "'PERSON10': 'But already the multi-target models which we have they are flexible in selection of the target.'",
        "'PERSON10': 'And they yeah -'",
        "'PERSON10': 'And they yeah, they can be used with any of of the with any language of the set of of source language, not only with one.'",
        "'PERSON10': 'So to conclude, this work package.'",
        "'PERSON10': 'We have the baselines, either bilingual, multilingual and with pivoting we cover all the language directions.'",
        "'PERSON10': 'And we are ready for a ORGANIZATION5 congress next year.'",
        "'PERSON10': 'The next next two task are the document-level translation and multi-target  research task.'",
        "'PERSON10': 'In last year we had six publications.'",
        "'PERSON10': 'This this year we have one published paper and ISL.'",
        "'PERSON10': 'One is under review.'",
        "'PERSON10': 'And we have one master thesis.'",
        "'PERSON10': 'The task on multi-source machine translation has just started and the flexible the task on flexible multilingual machine translation has not started yet as as was proposed.'",
        "'PERSON10': 'In the plan for so in the end we have no major devations from the plan.'",
        "'PERSON10': 'Thank you.'"
    ],
    "WP5 Progress report AM": [
        "'PERSON15': 'And eh, so we we have the, we have the automatic minuting task structure and eh, so we have the different modules for that.'",
        "'PERSON15': 'So the input which we have to subtask of the minuting medium.'",
        "'PERSON15': 'The very first subtask is the segmentation of the minuting transcripts.'",
        "'PERSON15': ' the text into segments and m- that would be couple of long sentences.'",
        "'PERSON15': 'And important thing here is to keep the semantically related phrases eh, in each segment.'",
        "'PERSON15': 'And next we have the segment level summarization.'",
        "'PERSON15': 'It's just kind of the sentence compression process.'",
        "'PERSON15': 'And the third task is a transcript summarization which is the which is the generation of the overall ehm, minutes of the meeting.'",
        "'PERSON15': 'And -'",
        "'PERSON13': 'Yes -'",
        "'PERSON15': 'Here we aim to identify and collect the conclusion and the and the  phrases only.'",
        "'PERSON15': 'So yes, I'm  to that slide just now.'",
        "'PERSON15': 'And,so this is a  part which is already covered.'",
        "'PERSON15': 'And do this is a minuting task structure.'",
        "'PERSON15': 'We have this segmentation  strapped to be sent me to shoot us trying.'",
        "'PERSON15': 'The task is to split the sentences to segments.'",
        "'PERSON15': 'And that would be couple of sentences long.'",
        "'PERSON15': 'And so the main task is to automatically eh eh capture the couple of sentences of related phrases in each segment.'",
        "'PERSON15': 'And then to make this segment level summaries of each segment of the phrases.'",
        "'PERSON15': 'And then to eh generate the dialogue summaries for each of the generated phrases.'",
        "'PERSON15': 'And the last is topic matching.'",
        "'PERSON15': 'So let me just represent of all of them one by one.'",
        "'PERSON15': 'And so this is a this is the eh, eh, this is a  schematically '",
        "'PERSON15': 'So eh, I was describing the minuting module and eh, so talking about the the systematic view of it.'",
        "'PERSON15': 'Eh, so the very first eh is the is the input and eh in the input we have the dialogue transcripts and the empty agenda, which eh, which is the whole which is a whole minuting transcript and the predefined agenda with its topics.'",
        "'PERSON15': 'The dialogue transcript eh is probably messy and in the sense that it comes as an outcome from the ASR module.'",
        "'PERSON15': 'And there're probably lot of noises into it and so eh, we do we probably clean that first.'",
        "'PERSON15': 'And so the predefined agenda is the list of topics that are discussed and it may happen that certain topics of the agenda are not discussed at all.'",
        "'PERSON15': 'And other topics enlisted in the agenda may - may also be discussed and present in the transcript.'",
        "'PERSON15': 'So we have to be prepared in all the cases.'",
        "'PERSON15': 'And ehm so the the input is containing this dialogue transcript and empty agenda, and as similar to that output we have the dialogue minutes and the and the filled agenda which is eh, which is the ASR output.'",
        "'PERSON15': 'And the primary objective is the, is the minutes after entire transcript.'",
        "'PERSON15': 'So we want to have the filled agenda with the minutes as with the minute sentences matched to the corresponding agenda topics.'",
        "'PERSON15': 'And so ehm, so the shot- cutting scheme eh, which we have used there.'",
        "'PERSON15': 'So instead of the the text segmentation -'",
        "'PERSON15': 'So because when we get the out- when we get the output from the dialogue transcripts from the ASR module eh, we eh, we have all the we have to pre-process that data.So we, we will be needing that all the removing all unnecessary staff in tokenization and all that.'",
        "'PERSON15': 'So eh, what we have eh, what we have  done is, we have shortcut eh, the the scheme, and we have print the dialogue transcript we have directly eh moduled dialogue summarisation by eh, taking  eh, the transfer learning approach using that transforming model trained with the CNN and Daily media samples.'",
        "'PERSON15': 'And tested that on AMIT data set that we adapted.'",
        "'PERSON15': 'And eh, of course, the results were terrible that we had very low Roche score and eh, also very messy summaries .'",
        "'PERSON15': 'But eh, then here so ehm, I will I will share the results at the end of this.'",
        "'PERSON15': 'And eh so the the minuting module, which is it the first module, which is the text segmentation.'",
        "'PERSON15': 'Here we have the first subtask text segmentation of the whole transcript.'",
        "'PERSON15': 'Eh, before we start with the segmentation we actually perform the text cleaning steps like tokenization removal of messy '",
        "'PERSON15': 'The goal is actually to  the braking this spoken language text into segments, which are couple of consecutive eh, sentences.'",
        "'PERSON15': 'And eh, of course we have to take care of grammatical correctness of the produced segments.'",
        "'PERSON15': 'Eh, so we need an intelligent solution that resolves the grammatical correctness along with removing all the unnecessary eh elements from it, from the transcript.'",
        "'PERSON15': 'And,mm, the second module is segment summarization.'",
        "'PERSON15': 'And ehm, eh, the - in- in segment summarization eh, we eh took the segments of the summarized eh- of the summarized phrases.'",
        "'PERSON15': 'And this is technically sentence compression.'",
        "'PERSON15': 'Eventhough we eh we have several several sentences in each cluster and then we performed this dialogue summarization where we have one eeh, eeh, one s- one approach without the DNNs.'",
        "'PERSON15': 'And one we have with DNNs with the transformed model.'",
        "'PERSON15': 'So this is the eh, pilot experiment which was performed with the extracted summarization approach.'",
        "'PERSON15': 'So we had ehm, manual meeting minutes we pre-processed it '",
        "'PERSON15': 'So all of the words in the minute minutes were tagged with the part of speech '",
        "'PERSON15': 'And those were tokenized.'",
        "'PERSON15': 'And they were TDID scores.'",
        "'PERSON15': 'But only for the nouns and words.'",
        "'PERSON15': 'And then we are using using all those TDID scores there were eh, sentence scores so all the ehm all the word scores we combined with the sentences scores.'",
        "'PERSON15': 'And the most important sentence were chosen based on the information retention of ehm the summari-summarization we need.'",
        "'PERSON15': 'And, eh, that's how we got the summarize minutes.'",
        "'PERSON15': 'And these were the results from that meeting eh, eh so from the experiment we did.'",
        "'PERSON15': 'So eh, this is a meeting minutes from PROJECT1 project.'",
        "'PERSON15': 'And this is the this is the candidate summary.'",
        "'PERSON15': 'Eh, so we had this eh, mm, as an output, which is, which is really not good.'",
        "'PERSON15': '\"When ORGANIZATION1 I went on ORGANIZATION1\"'",
        "'PERSON15': 'This is not making any sense too.'",
        "'PERSON15': 'But this is the output from the extracted summarization.'",
        "'PERSON15': 'And eh, this is the reference summary ORGANIZATION1 people capacity, which is fifteen people .'",
        "'PERSON15': 'And this is a Rouge score for  the ef and the pricism and the recall.'",
        "'PERSON15': 'And eh, the summary is eh Rouge eh which is zero point zero for  and the pricism be zero point one.'",
        "'PERSON15': 'And the recall to be zero point eh three two.'",
        "'PERSON15': 'And the BLEU score came up to be seventy point four percent.'",
        "'PERSON15': 'And eh so probably by these extracted results we eh we adopted the extractive summarization approach, where we used eh the transformer model and eh eh transformer model to grade the results.'",
        "'PERSON15': 'And eh, I have the results that as well, for the transformer model.'",
        "'PERSON15': 'So these're the results for the transformer model.'",
        "'PERSON15': 'And eh, this is the this is ROUGE score for it.'",
        "'PERSON15': 'Ehm, and this is the reference sentence we had from the from the transformer model.'",
        "'PERSON15': 'The remote will only control eh televisions and eh, this is a candidate.'",
        "'PERSON15': 'So this is the generated summary.'",
        "'PERSON15': 'And if you can see this eh, th- there's similarity between the reference and candidate is eh, is is eh,  is eh eh a little but not eh, making that made sense.'",
        "'PERSON15': 'Because the sense is not captured .'",
        "'PERSON15': 'And so this is the eh, these these are our initial attempts for the for the the the dialogue summarization.'",
        "'PERSON15': 'But when we talk about the experiment.'",
        "'PERSON15': 'So we're realized that the extracted approach is not eh, generating  summaries for ah, ehm for the minutes, meeting minutes.'",
        "'PERSON15': 'Because if - when you when you talk about ah, meeting minutes, eh, we have aligned sentences lik  \"yeah\" \"okay\" .'",
        "'PERSON15': 'And so there were a lot of sentences like that, and when you when you summarized that you get eh, so many words, which which which are eh, irrelevant to the to the summarize results.'",
        "'PERSON15': 'And eh, so probably I think we'll be able to achieve eh more good scores.'",
        "'PERSON15': 'And more ehm semantically eh, sensible is summarized summarize results eh, as candidate eh summary.'",
        "'PERSON15': 'And eh, so eh the the so we her- we or - here at the dialogue summarization right now.'",
        "'PERSON15': 'And then we are gonna do this agenda completion which is going to have the the filled agendas along with the dialogue minutes.'",
        "'PERSON15': 'Which will be compiled with the dialogue minutes.So the agendas will be eh the first will be agenda to fill up the agenda the and then to compile those minutes with the agenda.'",
        "'PERSON15': 'And ah, then we have this work on the similarity of minutes.'",
        "'PERSON15': 'So given to two minutes we have to we have to see that whether the both minutes are from the same meeting or they both are from the different meetings.'",
        "'PERSON15': 'Eh, so we we did some testing on eh, eh this Jacquard similarity which gave us a a score of seventy point two.'",
        "'PERSON15': 'And then there was minutes from different meeting, which was sixty three point five.'",
        "'PERSON15': 'And then we have this CountVec Cosine similarity which was seventy two point six and the minutes from different meeting point, three point seven.'",
        "'PERSON15': 'And we also tested it for eh the other word embedings along with Cosine similarities different word embeddings.'",
        "'PERSON15': 'So, eh, but when you when you eh eh manually see those minutes generated by two different annotators.'",
        "'PERSON15': 'Eh, they are probably eh, t- eh they are probably not eh, same.'",
        "'PERSON15': 'And eh, eh so eh, we are actually developing designing and developing eh deep neural network framework for the similarity measures to capture the semantic sense of eh the summarized meetings.'",
        "'PERSON15': 'Ee eh, so eh I would eh and the next plan is to eh, is is eh is is for the shared task in two thousand and twenty one.'",
        "'PERSON15': 'And eh, we have eh eh PERSON11 for that.'",
        "'PERSON15': 'And I would like to invite PERSON11 to share his his plans for eh for the shared task.'",
        "'PERSON15': 'PERSON11 are you there?'",
        "'PERSON15': 'Can you - eh?'",
        "'PERSON15': 'Can you sha-'",
        "'PERSON11': 'Hi, hi.'",
        "'PERSON11': 'Can you eh, can you hear?'",
        "'PERSON15': 'Yes.'",
        "'PERSON15': 'Yes, yes  we can hear you'",
        "'PERSON11': 'Okay.'",
        "'PERSON11': 'So,hi everyone.'",
        "'PERSON11': 'This is PERSON11.'",
        "'PERSON11': 'So eh, we're, so the final eh goal of this particular  is to organise the shared task eh in two thousand twenty one.'",
        "'PERSON11': 'So eh, we are just on the planning phase for the first shared task on automatic minuting.'",
        "'PERSON11': 'And we have checked out some potential venues where we could propose this.'",
        "'PERSON11': 'One is that Interspeech which would be proposal deadline will be some time in November.'",
        "'PERSON11': 'And there is SIGDail and eh followed by the IEEE workshop.'",
        "'PERSON11': 'So as eh as we already eh discussed that we have on mostly a hundred of news data.'",
        "'PERSON11': 'And data for the transcripts and the minutes.'",
        "'PERSON11': 'And there are a few other works that we can figure to decide on the evaluation measures of the submissions both manual and automatic.'",
        "'PERSON11': 'Followed by eh prepairing for the call for submissions, internal systems runs, eh evaluation scripts and setting up of the submission portal.'",
        "'PERSON11': 'So can we go to a next slide?'",
        "'PERSON15': 'Yes.'",
        "'PERSON11': 'Yeah, so this is just the the initial shared task that we have in our mind.'",
        "'PERSON11': 'So the task A is to like identify if the minute is from the given transcript when only the transcript and minute is given.'",
        "'PERSON11': 'The task B is like if two minutes are corresponding to the same meeting if we have just two minutes ehm as an input.'",
        "'PERSON11': 'And the task C is definitely the core task, that we generate the meeting minutes from the transcript from.'",
        "'PERSON11': 'And eh, finally we have the task D where are given the transcript and a set of pre-defined agenda items and we automatically slot- fill the agendas with the minutes.'",
        "'PERSON11': 'So it's not necessary that we propose all these tasks in IEEE venue.'",
        "'PERSON11': 'But this is what we have started to work at.'"
    ]
}